{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 13:02:47.278170: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-19 13:02:47.284023: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-19 13:02:47.299009: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-19 13:02:47.326788: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-19 13:02:47.335013: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-19 13:02:47.358544: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-19 13:02:48.968781: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import scipy\n",
    "import tensorflow_io as tfio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/focus/Bureau/Audio_Node/src/resources/ray_audio/audioset-download/audioset/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_164146/3904008273.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/audioset-download/audioset'\u001b[0m  \u001b[0;31m# Replace with your dataset path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mresample_audio_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_sample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_164146/3904008273.py\u001b[0m in \u001b[0;36mresample_audio_files\u001b[0;34m(dataset_path, desired_sample_rate)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msplit_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mclass_folder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mclass_folder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0maudio_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_folder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/focus/Bureau/Audio_Node/src/resources/ray_audio/audioset-download/audioset/train'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io.wavfile as wavfile\n",
    "import scipy.signal\n",
    "\n",
    "def ensure_sample_rate(original_sample_rate, waveform, desired_sample_rate=16000):\n",
    "    \"\"\"Resample waveform if required.\"\"\"\n",
    "    if original_sample_rate != desired_sample_rate:\n",
    "        desired_length = int(round(float(len(waveform)) / original_sample_rate * desired_sample_rate))\n",
    "        waveform = scipy.signal.resample(waveform, desired_length)\n",
    "    return desired_sample_rate, waveform\n",
    "\n",
    "def resample_audio_files(dataset_path, desired_sample_rate=16000):\n",
    "    # Iterate through train and test folders\n",
    "    for split in ['train', 'test']:\n",
    "        split_folder = os.path.join(dataset_path, split)\n",
    "        for class_folder in os.listdir(split_folder):\n",
    "            class_folder_path = os.path.join(split_folder, class_folder)\n",
    "            for audio_file in os.listdir(class_folder_path):\n",
    "                if audio_file.endswith('.wav'):  # Process only .wav files\n",
    "                    audio_path = os.path.join(class_folder_path, audio_file)\n",
    "                    \n",
    "                    # Read the audio file\n",
    "                    original_sample_rate, waveform = wavfile.read(audio_path)\n",
    "                    \n",
    "                    # Resample the audio if needed\n",
    "                    new_sample_rate, new_waveform = ensure_sample_rate(original_sample_rate, waveform, desired_sample_rate)\n",
    "                    \n",
    "                    # Save the resampled audio\n",
    "                    wavfile.write(audio_path, new_sample_rate, new_waveform.astype('int16'))  # Ensure correct data type\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = '/home/focus/Bureau/Audio_Node/src/resources/ray_audio/audioset-download/audioset'  # Replace with your dataset path\n",
    "    resample_audio_files(dataset_path, desired_sample_rate=16000)\n",
    "    print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for loading audio files and making sure the sample rate is correct.\n",
    "\n",
    "@tf.function\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    \n",
    "    return wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech\n",
      "Child speech, kid speaking\n",
      "Conversation\n",
      "Narration, monologue\n",
      "Babbling\n",
      "Speech synthesizer\n",
      "Shout\n",
      "Bellow\n",
      "Whoop\n",
      "Yell\n",
      "Children shouting\n",
      "Screaming\n",
      "Whispering\n",
      "Laughter\n",
      "Baby laughter\n",
      "Giggle\n",
      "Snicker\n",
      "Belly laugh\n",
      "Chuckle, chortle\n",
      "Crying, sobbing\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "class_map_path = yamnet_model.class_map_path().numpy().decode('utf-8')\n",
    "class_names =list(pd.read_csv(class_map_path)['display_name'])\n",
    "\n",
    "for name in class_names[:20]:\n",
    "  print(name)\n",
    "print('...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_directories(base_path, class_folders):\n",
    "    # List to hold information about each file\n",
    "    data = []\n",
    "    \n",
    "    # Loop through each class folder\n",
    "    for class_name in class_folders:\n",
    "        class_path = os.path.join(base_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            # List all .wav files in the class folder\n",
    "            for filename in os.listdir(class_path):\n",
    "                if filename.endswith('.wav'):\n",
    "                    file_path = os.path.join(class_path, filename)\n",
    "                    data.append({'filename': file_path, 'category': class_name})\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "base_data_path = '/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/'\n",
    "class_folders = ['Speech', 'Silence', 'Music', 'Beep', 'Robot_moving']\n",
    "df = create_dataframe_from_directories(base_data_path, class_folders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              filename      category  class_id\n",
      "0    /home/focus/Bureau/Audio_Node/src/resources/ra...        Speech         0\n",
      "1    /home/focus/Bureau/Audio_Node/src/resources/ra...        Speech         0\n",
      "2    /home/focus/Bureau/Audio_Node/src/resources/ra...        Speech         0\n",
      "3    /home/focus/Bureau/Audio_Node/src/resources/ra...        Speech         0\n",
      "4    /home/focus/Bureau/Audio_Node/src/resources/ra...        Speech         0\n",
      "..                                                 ...           ...       ...\n",
      "479  /home/focus/Bureau/Audio_Node/src/resources/ra...  Robot_moving         4\n",
      "480  /home/focus/Bureau/Audio_Node/src/resources/ra...  Robot_moving         4\n",
      "481  /home/focus/Bureau/Audio_Node/src/resources/ra...  Robot_moving         4\n",
      "482  /home/focus/Bureau/Audio_Node/src/resources/ra...  Robot_moving         4\n",
      "483  /home/focus/Bureau/Audio_Node/src/resources/ra...  Robot_moving         4\n",
      "\n",
      "[484 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define your classes and map them to IDs\n",
    "my_classes = ['Speech', 'Silence', 'Music', 'Beep', 'Robot_moving']\n",
    "map_class_to_id = {cls: idx for idx, cls in enumerate(my_classes)}\n",
    "\n",
    "# Filter DataFrame for specified classes (if needed)\n",
    "filtered_df = df[df['category'].isin(my_classes)]\n",
    "\n",
    "# Map class names to IDs\n",
    "filtered_df['class_id'] = filtered_df['category'].apply(lambda name: map_class_to_id[name])\n",
    "\n",
    "# Optionally, add a full path column if needed\n",
    "#filtered_df['full_path'] = filtered_df['filename'].apply(lambda row: os.path.abspath(row))\n",
    "\n",
    "# Display the DataFrame\n",
    "print(filtered_df.head(550))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'Speech')\n",
      "(1, 'Silence')\n",
      "(2, 'Music')\n",
      "(3, 'Beep')\n",
      "(4, 'Robot_moving')\n"
     ]
    }
   ],
   "source": [
    "for i in enumerate(my_classes):\n",
    "\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1K1rV9kFs6I_30.0-40.0.wav', Class ID = 2\n",
      "Sample 2: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1NEybsmFECg_30.0-40.0.wav', Class ID = 2\n",
      "Sample 3: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-V4WO7a8Lbk_70.0-80.0.wav', Class ID = 1\n",
      "Sample 4: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/74kJeRfUN0c_30.0-40.0.wav', Class ID = 3\n",
      "Sample 5: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-1hvn3ZCTAU_0.0-10.0.wav', Class ID = 1\n",
      "Sample 6: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/N5NGtmtnz_c_0.0-10.0.wav', Class ID = 0\n",
      "Sample 7: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/2ZfwEg4JaiU_0.0-10.0.wav', Class ID = 0\n",
      "Sample 8: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0x6chChxzV0_30.0-40.0.wav', Class ID = 2\n",
      "Sample 9: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0WWuZRd-O3c_0.0-10.0.wav', Class ID = 2\n",
      "Sample 10: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/j2bpPTTUdVw_0.0-2.0.wav', Class ID = 3\n",
      "Sample 11: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/OrXAi1ckgnY_10.0-20.0.wav', Class ID = 3\n",
      "Sample 12: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-WX7nQcZPVQ_30.0-40.0.wav', Class ID = 2\n",
      "Sample 13: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/26.wav', Class ID = 4\n",
      "Sample 14: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-J3Ybsqrgws_0.0-10.0.wav', Class ID = 0\n",
      "Sample 15: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0M7nETLOsKQ_30.0-40.0.wav', Class ID = 2\n",
      "Sample 16: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/BWeI-0CkL90_70.0-80.0.wav', Class ID = 3\n",
      "Sample 17: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1l37vMB7dic_190.0-200.0.wav', Class ID = 0\n",
      "Sample 18: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-sSVQrnvyIk_30.0-40.0.wav', Class ID = 2\n",
      "Sample 19: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/SkXXjcw9sJI_30.0-40.0.wav', Class ID = 3\n",
      "Sample 20: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/0L7-8yqgMEo_130.0-140.0.wav', Class ID = 0\n",
      "Sample 21: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/-7aNPr1x2aQ_18.0-28.0.wav', Class ID = 3\n",
      "Sample 22: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/CX60rMtVV6Q_30.0-40.0.wav', Class ID = 3\n",
      "Sample 23: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/RtWBKpmOmpg_380.0-390.0.wav', Class ID = 3\n",
      "Sample 24: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/240RfDRitx8_220.0-230.0.wav', Class ID = 2\n",
      "Sample 25: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-ayiPNqVg8A_30.0-40.0.wav', Class ID = 1\n",
      "Sample 26: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/-SiNctMT5vE_5.0-15.0.wav', Class ID = 3\n",
      "Sample 27: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/FPywV51u0qo_0.0-9.0.wav', Class ID = 3\n",
      "Sample 28: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/NI9slHxNZwg_30.0-40.0.wav', Class ID = 3\n",
      "Sample 29: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/A0E_UiD-fR4_0.0-10.0.wav', Class ID = 3\n",
      "Sample 30: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/5f9gPcJD5Ak_230.0-240.0.wav', Class ID = 1\n",
      "Sample 31: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/DJlmqt2fEXg_14.0-24.0.wav', Class ID = 3\n",
      "Sample 32: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/P4qd8uodw_M_0.0-10.0.wav', Class ID = 3\n",
      "Sample 33: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/grIP4c56AsM_0.0-10.0.wav', Class ID = 1\n",
      "Sample 34: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/07yWAi5Wkdo_30.0-40.0.wav', Class ID = 1\n",
      "Sample 35: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/OtA7ez85yP8_20.0-30.0.wav', Class ID = 3\n",
      "Sample 36: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/NsySbsVUvn8_30.0-40.0.wav', Class ID = 3\n",
      "Sample 37: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0I_Pi3zt4WY_0.0-10.0.wav', Class ID = 2\n",
      "Sample 38: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/695nvt2cbP8_30.0-40.0.wav', Class ID = 0\n",
      "Sample 39: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-XN0NtrnfMY_30.0-40.0.wav', Class ID = 2\n",
      "Sample 40: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/KE0XRUeEM5Y_30.0-40.0.wav', Class ID = 3\n",
      "Sample 41: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/EEceqO2ewu8_70.0-80.0.wav', Class ID = 3\n",
      "Sample 42: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/97ddBh0eOiE_530.0-540.0.wav', Class ID = 0\n",
      "Sample 43: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-U3Xh6Fsw50_0.0-10.0.wav', Class ID = 0\n",
      "Sample 44: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/DGooKeXsB-A_0.0-7.0.wav', Class ID = 3\n",
      "Sample 45: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/CBFq-G-Tigg_0.0-10.0.wav', Class ID = 3\n",
      "Sample 46: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/5bjiFUed8gw_30.0-40.0.wav', Class ID = 1\n",
      "Sample 47: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0abfTrxjX-4_30.0-40.0.wav', Class ID = 2\n",
      "Sample 48: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/0Gj0gGPGlMA_0.0-10.0.wav', Class ID = 0\n",
      "Sample 49: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-Jam3cjbeFQ_30.0-40.0.wav', Class ID = 0\n",
      "Sample 50: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/A3EA-y0Vq3g_0.0-6.0.wav', Class ID = 3\n",
      "Sample 51: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/0v--fTVAWE8_170.0-180.0.wav', Class ID = 0\n",
      "Sample 52: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-SG-pxdszAY_0.0-10.0.wav', Class ID = 1\n",
      "Sample 53: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/19Pp9QEw17U_30.0-40.0.wav', Class ID = 2\n",
      "Sample 54: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/11.wav', Class ID = 4\n",
      "Sample 55: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/2xcTEoO2PpE_180.0-190.0.wav', Class ID = 0\n",
      "Sample 56: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-8Th09Uo1-k_0.0-10.0.wav', Class ID = 1\n",
      "Sample 57: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/4hjjHLIVZ50_12.0-22.0.wav', Class ID = 0\n",
      "Sample 58: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-C49OrWCztI_0.0-10.0.wav', Class ID = 1\n",
      "Sample 59: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/5-DxwyeNA34_30.0-40.0.wav', Class ID = 0\n",
      "Sample 60: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/7aKBgag7ylE_0.0-9.0.wav', Class ID = 0\n",
      "Sample 61: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/a9i5yixsJbk_0.0-10.0.wav', Class ID = 3\n",
      "Sample 62: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1TB3-XSom_A_30.0-40.0.wav', Class ID = 0\n",
      "Sample 63: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/--aE2O5G5WE_0.0-10.0.wav', Class ID = 2\n",
      "Sample 64: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/--aE2O5G5WE_0.0-10.0.wav', Class ID = 0\n",
      "Sample 65: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/TbtvRtdHRq4_10.0-20.0.wav', Class ID = 3\n",
      "Sample 66: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/9yY9mjvbHEg_240.0-250.0.wav', Class ID = 0\n",
      "Sample 67: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/23.wav', Class ID = 4\n",
      "Sample 68: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/04_gDOH7ibQ_30.0-40.0.wav', Class ID = 1\n",
      "Sample 69: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/e0U_yQITBks_30.0-40.0.wav', Class ID = 3\n",
      "Sample 70: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-AswFDuOptQ_0.0-10.0.wav', Class ID = 2\n",
      "Sample 71: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/06IU9WsEp3s_130.0-140.0.wav', Class ID = 2\n",
      "Sample 72: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-D_ljLTbCK0_220.0-230.0.wav', Class ID = 2\n",
      "Sample 73: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/0HVZPTe7MNQ_22.0-32.0.wav', Class ID = 3\n",
      "Sample 74: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/9lrOSagI8as_0.0-10.0.wav', Class ID = 0\n",
      "Sample 75: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-M_5w6KKfgQ_0.0-10.0.wav', Class ID = 2\n",
      "Sample 76: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/26HLgXWF-Co_30.0-40.0.wav', Class ID = 2\n",
      "Sample 77: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/L3GPuOONhdQ_0.0-10.0.wav', Class ID = 3\n",
      "Sample 78: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/SyY1hl7cOMU_210.0-220.0.wav', Class ID = 0\n",
      "Sample 79: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-bosH8UgUdU_280.0-290.0.wav', Class ID = 0\n",
      "Sample 80: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-ItCGHv_9Gs_3.0-13.0.wav', Class ID = 1\n",
      "Sample 81: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/4fWOzHahaPQ_310.0-320.0.wav', Class ID = 0\n",
      "Sample 82: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-fxh7jAJR8U_70.0-80.0.wav', Class ID = 2\n",
      "Sample 83: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/CZ0e-kD-sqI_23.0-33.0.wav', Class ID = 3\n",
      "Sample 84: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/JC2yWA-VZqs_30.0-40.0.wav', Class ID = 3\n",
      "Sample 85: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/06sLGiMrWlw_30.0-40.0.wav', Class ID = 2\n",
      "Sample 86: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/CEbUP-wPPqY_30.0-40.0.wav', Class ID = 3\n",
      "Sample 87: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-k0MWJUz4tU_0.0-4.0.wav', Class ID = 1\n",
      "Sample 88: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0HQCuY_XQa8_0.0-10.0.wav', Class ID = 2\n",
      "Sample 89: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/GCPvr-HKAx8_20.0-30.0.wav', Class ID = 3\n",
      "Sample 90: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1_dN8IWAC8s_30.0-40.0.wav', Class ID = 0\n",
      "Sample 91: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/CSfbHfwsIVE_20.0-30.0.wav', Class ID = 3\n",
      "Sample 92: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-0eWfAENhng_0.0-10.0.wav', Class ID = 1\n",
      "Sample 93: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/07eQfg1IXzw_0.0-10.0.wav', Class ID = 1\n",
      "Sample 94: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/KQxm8jFOTk4_0.0-5.0.wav', Class ID = 3\n",
      "Sample 95: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/rNUtYf6EdW8_470.0-480.0.wav', Class ID = 0\n",
      "Sample 96: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1J-v2SVsSPQ_21.0-31.0.wav', Class ID = 0\n",
      "Sample 97: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1KN3GrwhY8c_420.0-430.0.wav', Class ID = 2\n",
      "Sample 98: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/GgThj4RfZ2M_0.0-10.0.wav', Class ID = 3\n",
      "Sample 99: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-rAhS48FkYw_30.0-40.0.wav', Class ID = 2\n",
      "Sample 100: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/4Pc9rWewLIY_12.0-22.0.wav', Class ID = 0\n",
      "Sample 101: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/07eQfg1IXzw_0.0-10.0.wav', Class ID = 2\n",
      "Sample 102: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/Fq107k8_9vk_0.0-1.0.wav', Class ID = 3\n",
      "Sample 103: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-orugG3hBr4_0.0-10.0.wav', Class ID = 2\n",
      "Sample 104: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/Bc5ou-HXXWE_240.0-250.0.wav', Class ID = 3\n",
      "Sample 105: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-uLJl3o_AZw_30.0-40.0.wav', Class ID = 2\n",
      "Sample 106: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/3-Lvdqfmj2U_30.0-40.0.wav', Class ID = 0\n",
      "Sample 107: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/27.wav', Class ID = 4\n",
      "Sample 108: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-ETHxO8vrAg_30.0-40.0.wav', Class ID = 2\n",
      "Sample 109: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/NdTrCKr3lFI_0.0-4.0.wav', Class ID = 3\n",
      "Sample 110: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1ZekxAeKfPc_0.0-10.0.wav', Class ID = 2\n",
      "Sample 111: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-hOtfglQyeg_290.0-300.0.wav', Class ID = 1\n",
      "Sample 112: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/R29JgE6cviY_0.0-9.0.wav', Class ID = 3\n",
      "Sample 113: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0QDYPyHwLhk_390.0-400.0.wav', Class ID = 2\n",
      "Sample 114: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/BFl3EjoeaIU_10.0-20.0.wav', Class ID = 3\n",
      "Sample 115: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/DcxZeZ7063A_20.0-30.0.wav', Class ID = 3\n",
      "Sample 116: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/JyWjg9wIGQo_0.0-10.0.wav', Class ID = 3\n",
      "Sample 117: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-M_5w6KKfgQ_0.0-10.0.wav', Class ID = 0\n",
      "Sample 118: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/5.wav', Class ID = 4\n",
      "Sample 119: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1jyM3quZ0h0_70.0-80.0.wav', Class ID = 2\n",
      "Sample 120: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/RWUQTiVU8rE_0.0-10.0.wav', Class ID = 3\n",
      "Sample 121: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-xUhOdzwLtw_0.0-10.0.wav', Class ID = 0\n",
      "Sample 122: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/G8E2ahrxkxA_360.0-370.0.wav', Class ID = 3\n",
      "Sample 123: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/HA05491bCc8_0.0-10.0.wav', Class ID = 3\n",
      "Sample 124: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/FAE0mEviy1c_290.0-300.0.wav', Class ID = 3\n",
      "Sample 125: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/DHIhsTWxsKE_4.0-14.0.wav', Class ID = 3\n",
      "Sample 126: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1i_gKILNaaA_30.0-40.0.wav', Class ID = 0\n",
      "Sample 127: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/2-APL9g4ito_140.0-150.0.wav', Class ID = 0\n",
      "Sample 128: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/1jyBARHxmlc_160.0-170.0.wav', Class ID = 1\n",
      "Sample 129: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/WxEcP4gUfyU_0.0-10.0.wav', Class ID = 3\n",
      "Sample 130: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/5tOj-p8ANmM_0.0-10.0.wav', Class ID = 0\n",
      "Sample 131: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/SezDCwnaTn0_0.0-10.0.wav', Class ID = 3\n",
      "Sample 132: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-mA_bqD1tgU_30.0-40.0.wav', Class ID = 2\n",
      "Sample 133: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/1--9ZSW-7Rg_210.0-220.0.wav', Class ID = 1\n",
      "Sample 134: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/90rgiP6MPM8_0.0-10.0.wav', Class ID = 0\n",
      "Sample 135: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/OpRGvI2y0_o_2.0-12.0.wav', Class ID = 3\n",
      "Sample 136: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/0Zh8HjR0CbM_25.0-35.0.wav', Class ID = 0\n",
      "Sample 137: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-xeYpMf97eU_180.0-190.0.wav', Class ID = 0\n",
      "Sample 138: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-8H4GKg-mYQ_30.0-40.0.wav', Class ID = 2\n",
      "Sample 139: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/5-AK6M3KZr8_21.0-31.0.wav', Class ID = 0\n",
      "Sample 140: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0qQL0t97qf8_110.0-120.0.wav', Class ID = 2\n",
      "Sample 141: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/DMmlXBR5hs4_2.0-12.0.wav', Class ID = 3\n",
      "Sample 142: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/0-eQDarWcPE_30.0-40.0.wav', Class ID = 1\n",
      "Sample 143: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1IK4OeOqAEo_30.0-40.0.wav', Class ID = 2\n",
      "Sample 144: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/D14QMp6dz0U_2.0-12.0.wav', Class ID = 3\n",
      "Sample 145: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/-Ehq-x_csng_0.0-10.0.wav', Class ID = 3\n",
      "Sample 146: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/2BzEcX91rgc_30.0-40.0.wav', Class ID = 2\n",
      "Sample 147: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/7.wav', Class ID = 4\n",
      "Sample 148: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/JzIrFGR9xsk_0.0-8.0.wav', Class ID = 3\n",
      "Sample 149: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/Zk5Nx_uVFIk_0.0-10.0.wav', Class ID = 1\n",
      "Sample 150: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/NkyPkwTHntk_0.0-9.0.wav', Class ID = 3\n",
      "Sample 151: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-zW3EwMuywE_0.0-10.0.wav', Class ID = 1\n",
      "Sample 152: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/2TPXZlM7ZbM_350.0-360.0.wav', Class ID = 1\n",
      "Sample 153: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/0CvyKoMBuB4_0.0-10.0.wav', Class ID = 0\n",
      "Sample 154: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/0Q5mzNz2hiA_0.0-10.0.wav', Class ID = 1\n",
      "Sample 155: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1ejb5TtkhY8_120.0-130.0.wav', Class ID = 2\n",
      "Sample 156: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/6i8NJqD6sos_280.0-290.0.wav', Class ID = 0\n",
      "Sample 157: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/-EcQWP49XO0_480.0-490.0.wav', Class ID = 3\n",
      "Sample 158: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/6vcpZCbAd1U_1.0-11.0.wav', Class ID = 0\n",
      "Sample 159: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/31.wav', Class ID = 4\n",
      "Sample 160: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/JBCyJiXVyFg_470.0-480.0.wav', Class ID = 3\n",
      "Sample 161: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/njXNuSGZnz4_0.0-10.0.wav', Class ID = 0\n",
      "Sample 162: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/0GBVaUPTTSw_0.0-10.0.wav', Class ID = 1\n",
      "Sample 163: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0g43Ad6e-40_30.0-40.0.wav', Class ID = 2\n",
      "Sample 164: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-LqWxIHGXew_10.0-20.0.wav', Class ID = 0\n",
      "Sample 165: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/Fze-R31J6qs_20.0-30.0.wav', Class ID = 3\n",
      "Sample 166: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/0QDYPyHwLhk_390.0-400.0.wav', Class ID = 0\n",
      "Sample 167: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/TNXMCfdtCCc_30.0-40.0.wav', Class ID = 3\n",
      "Sample 168: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/CI13y6bZYUw_30.0-40.0.wav', Class ID = 3\n",
      "Sample 169: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-pzwalZ0ub0_5.0-15.0.wav', Class ID = 0\n",
      "Sample 170: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/0d3kh_lETKc_100.0-110.0.wav', Class ID = 0\n",
      "Sample 171: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/2qJ-efHMACE_30.0-40.0.wav', Class ID = 1\n",
      "Sample 172: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/mtMPZmAVUCo_0.0-8.0.wav', Class ID = 3\n",
      "Sample 173: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-Z6uzjuZ9fs_20.0-30.0.wav', Class ID = 1\n",
      "Sample 174: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/0CDP7zl6wCQ_30.0-40.0.wav', Class ID = 1\n",
      "Sample 175: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-DlMeIHejZk_190.0-200.0.wav', Class ID = 1\n",
      "Sample 176: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-5-vmt2iKT0_30.0-40.0.wav', Class ID = 0\n",
      "Sample 177: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/WTsJrsuYPO0_4.0-14.0.wav', Class ID = 3\n",
      "Sample 178: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1c5rSQsqmBE_0.0-10.0.wav', Class ID = 0\n",
      "Sample 179: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/Cz4fR913zFE_30.0-40.0.wav', Class ID = 3\n",
      "Sample 180: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/5L-sKSpgHwk_30.0-40.0.wav', Class ID = 0\n",
      "Sample 181: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-M-6VinyMiY_30.0-40.0.wav', Class ID = 2\n",
      "Sample 182: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/9PXdzAsN-Ss_0.0-10.0.wav', Class ID = 1\n",
      "Sample 183: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/Ea3K5y3eT38_0.0-9.0.wav', Class ID = 3\n",
      "Sample 184: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-En5nC5Tka4_30.0-40.0.wav', Class ID = 0\n",
      "Sample 185: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/89cgiPVJZ_4_0.0-10.0.wav', Class ID = 0\n",
      "Sample 186: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-eEhWLICanU_160.0-170.0.wav', Class ID = 0\n",
      "Sample 187: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-eEhWLICanU_160.0-170.0.wav', Class ID = 2\n",
      "Sample 188: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/DoCRoP7ojMU_9.0-19.0.wav', Class ID = 3\n",
      "Sample 189: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/0auuJJiE2xI_30.0-40.0.wav', Class ID = 0\n",
      "Sample 190: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-U_sL_gAaXA_0.0-10.0.wav', Class ID = 0\n",
      "Sample 191: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/5F7MMaPJqMc_0.0-5.0.wav', Class ID = 1\n",
      "Sample 192: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/07m7_xBjvPY_80.0-90.0.wav', Class ID = 0\n",
      "Sample 193: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/6kijTMUqcMI_0.0-10.0.wav', Class ID = 1\n",
      "Sample 194: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/18.wav', Class ID = 4\n",
      "Sample 195: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-xUhOdzwLtw_0.0-10.0.wav', Class ID = 2\n",
      "Sample 196: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/6O4Zpv-cAXY_0.0-7.0.wav', Class ID = 0\n",
      "Sample 197: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-oVYdOqefuk_70.0-80.0.wav', Class ID = 1\n",
      "Sample 198: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/S9sK-LDUk5Q_0.0-10.0.wav', Class ID = 3\n",
      "Sample 199: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/05OJDYeHLMc_30.0-40.0.wav', Class ID = 2\n",
      "Sample 200: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/2mEH2FUWUTg_30.0-40.0.wav', Class ID = 1\n",
      "Sample 201: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/B-Iw2S4E15w_370.0-380.0.wav', Class ID = 3\n",
      "Sample 202: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1CKGuGiDxYA_40.0-50.0.wav', Class ID = 2\n",
      "Sample 203: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/PKWkc9dTeP0_20.0-30.0.wav', Class ID = 3\n",
      "Sample 204: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/DAadfbrd0_A_1.0-11.0.wav', Class ID = 3\n",
      "Sample 205: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/0FTC0dpC9BA_0.0-10.0.wav', Class ID = 1\n",
      "Sample 206: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-QcXMPUNMeM_0.0-10.0.wav', Class ID = 0\n",
      "Sample 207: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/O57TyNLjblc_20.0-30.0.wav', Class ID = 3\n",
      "Sample 208: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/Cpv5OKzqEiI_10.0-20.0.wav', Class ID = 3\n",
      "Sample 209: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/15htpcg-ii4_230.0-240.0.wav', Class ID = 2\n",
      "Sample 210: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/NMWCnaPyHhg_1.0-11.0.wav', Class ID = 3\n",
      "Sample 211: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0T45fkKkCCk_30.0-40.0.wav', Class ID = 2\n",
      "Sample 212: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/DTtoHTthpRM_0.0-10.0.wav', Class ID = 3\n",
      "Sample 213: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1018edESAkw_0.0-10.0.wav', Class ID = 0\n",
      "Sample 214: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/0DgH-2g6Tmk_30.0-40.0.wav', Class ID = 1\n",
      "Sample 215: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-lUCohWH9xg_29.0-39.0.wav', Class ID = 0\n",
      "Sample 216: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1Is1xfDjZrw_30.0-40.0.wav', Class ID = 2\n",
      "Sample 217: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/9tlHzTPksMI_4.0-14.0.wav', Class ID = 1\n",
      "Sample 218: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/MwZD2K3wZnk_0.0-2.0.wav', Class ID = 3\n",
      "Sample 219: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/60dw27YRolU_90.0-100.0.wav', Class ID = 1\n",
      "Sample 220: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/0C8PTjL34Nw_0.0-10.0.wav', Class ID = 1\n",
      "Sample 221: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/EBm98fjWHU4_0.0-10.0.wav', Class ID = 3\n",
      "Sample 222: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1RVYmY1EFFI_30.0-40.0.wav', Class ID = 2\n",
      "Sample 223: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-XOINU-l1_o_90.0-100.0.wav', Class ID = 2\n",
      "Sample 224: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/0OLpIiSBlfc_60.0-70.0.wav', Class ID = 1\n",
      "Sample 225: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-yaLfRzoB4w_480.0-490.0.wav', Class ID = 1\n",
      "Sample 226: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/EuZjMYsCx5M_0.0-3.0.wav', Class ID = 3\n",
      "Sample 227: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/2hyHI8DNWD4_200.0-210.0.wav', Class ID = 0\n",
      "Sample 228: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/A3uHnpjXysE_8.0-18.0.wav', Class ID = 0\n",
      "Sample 229: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/JOfV4SjmDeQ_490.0-500.0.wav', Class ID = 3\n",
      "Sample 230: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-AswFDuOptQ_0.0-10.0.wav', Class ID = 0\n",
      "Sample 231: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/0kX9YFgnIh8_0.0-10.0.wav', Class ID = 3\n",
      "Sample 232: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/2XFwH-VGWjU_0.0-10.0.wav', Class ID = 0\n",
      "Sample 233: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/0Evtp8U6Vqk_0.0-10.0.wav', Class ID = 1\n",
      "Sample 234: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/2BzEcX91rgc_30.0-40.0.wav', Class ID = 0\n",
      "Sample 235: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/5s0oF2fMOtg_0.0-10.0.wav', Class ID = 0\n",
      "Sample 236: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-WCen368jnU_0.0-10.0.wav', Class ID = 1\n",
      "Sample 237: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/8DNABRM6e_8_0.0-10.0.wav', Class ID = 1\n",
      "Sample 238: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0UPY7ws-VFs_10.0-20.0.wav', Class ID = 2\n",
      "Sample 239: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/iAKUYTMv23Y_45.0-55.0.wav', Class ID = 3\n",
      "Sample 240: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-GbX8GUiLbw_430.0-440.0.wav', Class ID = 1\n",
      "Sample 241: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/6gAInizlVKw_60.0-70.0.wav', Class ID = 0\n",
      "Sample 242: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/TFWPqA9DMfc_0.0-10.0.wav', Class ID = 3\n",
      "Sample 243: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/H2xPKz3Uqu4_0.0-10.0.wav', Class ID = 3\n",
      "Sample 244: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0VsjSa1X7iA_30.0-40.0.wav', Class ID = 2\n",
      "Sample 245: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/3.wav', Class ID = 4\n",
      "Sample 246: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/2aUWpuKZ-GQ_0.0-10.0.wav', Class ID = 0\n",
      "Sample 247: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1wXZEzLFXCY_0.0-10.0.wav', Class ID = 2\n",
      "Sample 248: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-OIfyY2rRjE_530.0-540.0.wav', Class ID = 1\n",
      "Sample 249: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1ArUx6UCxe4_30.0-40.0.wav', Class ID = 2\n",
      "Sample 250: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-6ud_cE7TEQ_0.0-10.0.wav', Class ID = 1\n",
      "Sample 251: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/AjtWZ_viEzw_30.0-40.0.wav', Class ID = 3\n",
      "Sample 252: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/0StCxWx9dV8_30.0-40.0.wav', Class ID = 0\n",
      "Sample 253: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/2QcOD8uCu0E_0.0-10.0.wav', Class ID = 0\n",
      "Sample 254: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/85OY8T4UCkw_6.0-16.0.wav', Class ID = 0\n",
      "Sample 255: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-b6pKB99TKg_0.0-10.0.wav', Class ID = 0\n",
      "Sample 256: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/jH7BDWsU4zI_370.0-380.0.wav', Class ID = 3\n",
      "Sample 257: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/8mcBJ6Szz_M_0.0-10.0.wav', Class ID = 0\n",
      "Sample 258: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/2VMfJymq_lY_30.0-40.0.wav', Class ID = 0\n",
      "Sample 259: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/2bR0IRhqpNM_270.0-280.0.wav', Class ID = 1\n",
      "Sample 260: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/03kFLTZguBs_100.0-110.0.wav', Class ID = 0\n",
      "Sample 261: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/DEfWw06IO_k_0.0-10.0.wav', Class ID = 3\n",
      "Sample 262: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0ADP-O_V3vA_30.0-40.0.wav', Class ID = 2\n",
      "Sample 263: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/5bMHjP0EaWw_11.0-21.0.wav', Class ID = 0\n",
      "Sample 264: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/3FAIXEkxyBs_530.0-540.0.wav', Class ID = 0\n",
      "Sample 265: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-OaOY7-71ME_90.0-100.0.wav', Class ID = 2\n",
      "Sample 266: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0jXTBAGv9ZQ_140.0-150.0.wav', Class ID = 2\n",
      "Sample 267: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1Ziku4FLka4_30.0-40.0.wav', Class ID = 0\n",
      "Sample 268: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/4ZwGxgOwBUc_140.0-150.0.wav', Class ID = 0\n",
      "Sample 269: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/Aw2twjnBhBg_0.0-10.0.wav', Class ID = 3\n",
      "Sample 270: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/OT0BG3JDiWI_0.0-3.0.wav', Class ID = 3\n",
      "Sample 271: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-T-ZI1MZ44g_40.0-50.0.wav', Class ID = 0\n",
      "Sample 272: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/2hKS-hbOvY4_5.0-15.0.wav', Class ID = 0\n",
      "Sample 273: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/0-ZjaeDAvos_0.0-10.0.wav', Class ID = 0\n",
      "Sample 274: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0suNPEw298g_30.0-40.0.wav', Class ID = 2\n",
      "Sample 275: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/ArK2BXNXEhk_0.0-4.0.wav', Class ID = 3\n",
      "Sample 276: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/mJEmgYJ7Z4s_0.0-10.0.wav', Class ID = 0\n",
      "Sample 277: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/OQFhxgKDmLc_480.0-490.0.wav', Class ID = 3\n",
      "Sample 278: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/6VOGlqLeOzI_30.0-40.0.wav', Class ID = 0\n",
      "Sample 279: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1faN_f9Kj8Y_30.0-40.0.wav', Class ID = 2\n",
      "Sample 280: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/2-APL9g4ito_140.0-150.0.wav', Class ID = 2\n",
      "Sample 281: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/myRr2k_ktMU_30.0-40.0.wav', Class ID = 3\n",
      "Sample 282: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/7YAS-Qo_sjI_0.0-10.0.wav', Class ID = 0\n",
      "Sample 283: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-5S70zOSw30_30.0-40.0.wav', Class ID = 0\n",
      "Sample 284: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/NrV8foISX8A_40.0-50.0.wav', Class ID = 3\n",
      "Sample 285: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-EOb2W96aDs_21.0-31.0.wav', Class ID = 1\n",
      "Sample 286: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/11fNNN95_og_30.0-40.0.wav', Class ID = 2\n",
      "Sample 287: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/Cn0u4dhskoY_30.0-40.0.wav', Class ID = 3\n",
      "Sample 288: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/08YFRFx-g7s_30.0-40.0.wav', Class ID = 2\n",
      "Sample 289: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/KddGbfF5vV8_40.0-50.0.wav', Class ID = 3\n",
      "Sample 290: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/TBBXRQHKFcE_0.0-10.0.wav', Class ID = 0\n",
      "Sample 291: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/33_enN0Bsfs_440.0-450.0.wav', Class ID = 1\n",
      "Sample 292: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/V-t7x4K8pbI_0.0-10.0.wav', Class ID = 3\n",
      "Sample 293: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/EBNjRTOdE-8_0.0-10.0.wav', Class ID = 3\n",
      "Sample 294: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-uWB_lkFDhg_140.0-150.0.wav', Class ID = 0\n",
      "Sample 295: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/HFzP_6K2ReI_0.0-6.0.wav', Class ID = 3\n",
      "Sample 296: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-t_n44IaDBw_0.0-10.0.wav', Class ID = 0\n",
      "Sample 297: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/WdNu0Yh85bM_250.0-260.0.wav', Class ID = 1\n",
      "Sample 298: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/Dfs5pi7JuEM_25.0-35.0.wav', Class ID = 3\n",
      "Sample 299: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/GCbTs7bFpKI_260.0-270.0.wav', Class ID = 3\n",
      "Sample 300: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/26owMAFMWJw_0.0-8.0.wav', Class ID = 2\n",
      "Sample 301: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/Gj51Xebm8LQ_280.0-290.0.wav', Class ID = 3\n",
      "Sample 302: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/J01HOxspL3A_0.0-10.0.wav', Class ID = 3\n",
      "Sample 303: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/VHYxa5klYHw_3.0-13.0.wav', Class ID = 3\n",
      "Sample 304: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/01n2Gq4yroo_0.0-10.0.wav', Class ID = 1\n",
      "Sample 305: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/OQzIW7pTqc4_0.0-10.0.wav', Class ID = 3\n",
      "Sample 306: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/HscHTSXOcAI_0.0-10.0.wav', Class ID = 3\n",
      "Sample 307: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/AdW3WsQy7QY_170.0-180.0.wav', Class ID = 3\n",
      "Sample 308: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/2rPN7Ry_Hx8_200.0-210.0.wav', Class ID = 0\n",
      "Sample 309: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/sj238FA4c3s_0.0-10.0.wav', Class ID = 1\n",
      "Sample 310: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/JkUxrhrattc_1.0-11.0.wav', Class ID = 3\n",
      "Sample 311: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/08cBNU0KgWw_0.0-10.0.wav', Class ID = 1\n",
      "Sample 312: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1h2sb2xeCt8_30.0-40.0.wav', Class ID = 2\n",
      "Sample 313: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/L9eDYHjUk1k_90.0-100.0.wav', Class ID = 3\n",
      "Sample 314: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/2JNY2SaMk7s_30.0-40.0.wav', Class ID = 2\n",
      "Sample 315: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/46Mvf2FnAwg_140.0-150.0.wav', Class ID = 1\n",
      "Sample 316: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/1hJB8Fg5UKI_3.0-13.0.wav', Class ID = 1\n",
      "Sample 317: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/10.wav', Class ID = 4\n",
      "Sample 318: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/G6Vxrqfytrk_0.0-5.0.wav', Class ID = 3\n",
      "Sample 319: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/3qeBcAw5T8U_240.0-250.0.wav', Class ID = 1\n",
      "Sample 320: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/2MIXPd5lbc4_10.0-20.0.wav', Class ID = 0\n",
      "Sample 321: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-o0ZtQIkM60_30.0-40.0.wav', Class ID = 2\n",
      "Sample 322: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/FOVehMph9ec_0.0-10.0.wav', Class ID = 3\n",
      "Sample 323: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/0rAyrmm7vv0_30.0-40.0.wav', Class ID = 0\n",
      "Sample 324: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-0SdAVK79lg_30.0-40.0.wav', Class ID = 2\n",
      "Sample 325: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1y7lQSNaMjw_60.0-70.0.wav', Class ID = 0\n",
      "Sample 326: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/01WE0LVjyqA_10.0-20.0.wav', Class ID = 1\n",
      "Sample 327: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/UgDlY2t3l-k_9.0-19.0.wav', Class ID = 3\n",
      "Sample 328: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/22.wav', Class ID = 4\n",
      "Sample 329: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/066wxc3yZ5g_0.0-10.0.wav', Class ID = 1\n",
      "Sample 330: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/4i5h3aEgnnE_180.0-190.0.wav', Class ID = 1\n",
      "Sample 331: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-R9gJXtS07g_0.0-10.0.wav', Class ID = 2\n",
      "Sample 332: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1FnT0RrfMEA_30.0-40.0.wav', Class ID = 2\n",
      "Sample 333: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/CzO7nPdWLa4_80.0-90.0.wav', Class ID = 3\n",
      "Sample 334: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-WmL01c-4ZE_20.0-30.0.wav', Class ID = 0\n",
      "Sample 335: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-GB9OL7pf-E_320.0-330.0.wav', Class ID = 1\n",
      "Sample 336: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/0qZ3tI4nAZE_6.0-16.0.wav', Class ID = 0\n",
      "Sample 337: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/0KXI3QmISXM_30.0-40.0.wav', Class ID = 0\n",
      "Sample 338: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/14.wav', Class ID = 4\n",
      "Sample 339: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/91p58JxJNjU_0.0-10.0.wav', Class ID = 3\n",
      "Sample 340: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/LR2tjCZ-WNg_120.0-130.0.wav', Class ID = 3\n",
      "Sample 341: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/D7ZyOqwYpsI_60.0-70.0.wav', Class ID = 3\n",
      "Sample 342: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/-DhD6NQulug_30.0-40.0.wav', Class ID = 3\n",
      "Sample 343: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/BV994_HYw3M_6.0-16.0.wav', Class ID = 3\n",
      "Sample 344: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/17.wav', Class ID = 4\n",
      "Sample 345: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/00M9FhCet6s_100.0-110.0.wav', Class ID = 2\n",
      "Sample 346: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/TLuK4GRnjpo_40.0-50.0.wav', Class ID = 3\n",
      "Sample 347: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/HSPOzbV2rio_0.0-10.0.wav', Class ID = 3\n",
      "Sample 348: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/VZUeuxkYnT4_0.0-10.0.wav', Class ID = 3\n",
      "Sample 349: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/30.wav', Class ID = 4\n",
      "Sample 350: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/IU2ci3B9yFU_250.0-260.0.wav', Class ID = 3\n",
      "Sample 351: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/Q_aklWo1z2o_30.0-40.0.wav', Class ID = 3\n",
      "Sample 352: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-TvUb8THUq4_100.0-110.0.wav', Class ID = 2\n",
      "Sample 353: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-tmY1GEH3_Y_30.0-40.0.wav', Class ID = 2\n",
      "Sample 354: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0qtbbK5HVMw_330.0-340.0.wav', Class ID = 2\n",
      "Sample 355: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-UuEBhule84_350.0-360.0.wav', Class ID = 2\n",
      "Sample 356: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/28_dI7KHIf0_0.0-10.0.wav', Class ID = 0\n",
      "Sample 357: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/4AllUpjCvI4_280.0-290.0.wav', Class ID = 1\n",
      "Sample 358: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/W9gW1AYUa0A_10.0-20.0.wav', Class ID = 3\n",
      "Sample 359: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/N9o5ndRjP-c_0.0-10.0.wav', Class ID = 3\n",
      "Sample 360: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/na2sq-zkPmU_480.0-490.0.wav', Class ID = 1\n",
      "Sample 361: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/2QCxV6lFtXI_0.0-10.0.wav', Class ID = 2\n",
      "Sample 362: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/19.wav', Class ID = 4\n",
      "Sample 363: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-kkTpMU4QS8_30.0-40.0.wav', Class ID = 1\n",
      "Sample 364: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/LOm5adY6EEY_4.0-14.0.wav', Class ID = 3\n",
      "Sample 365: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/SVSBo065hmw_0.0-10.0.wav', Class ID = 0\n",
      "Sample 366: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/AMso8W3_2mk_30.0-40.0.wav', Class ID = 0\n",
      "Sample 367: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/-WfVfhKcZAo_10.0-20.0.wav', Class ID = 3\n",
      "Sample 368: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1zFcAqNQBZY_30.0-40.0.wav', Class ID = 0\n",
      "Sample 369: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/GiK9pJ3YRZc_0.0-10.0.wav', Class ID = 3\n",
      "Sample 370: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/CDwk_DbprX4_30.0-40.0.wav', Class ID = 3\n",
      "Sample 371: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-QivqOnaPIc_100.0-110.0.wav', Class ID = 0\n",
      "Sample 372: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/19Pp9QEw17U_30.0-40.0.wav', Class ID = 1\n",
      "Sample 373: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/ENSQtJeJ1-U_0.0-10.0.wav', Class ID = 3\n",
      "Sample 374: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/Fe19Ppb5uIs_490.0-500.0.wav', Class ID = 3\n",
      "Sample 375: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/04XfIdeUJ7w_0.0-10.0.wav', Class ID = 1\n",
      "Sample 376: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/1HPYHsdLYCQ_28.0-38.0.wav', Class ID = 1\n",
      "Sample 377: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/161-FGTcecc_120.0-130.0.wav', Class ID = 0\n",
      "Sample 378: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-lFwchGSkes_30.0-40.0.wav', Class ID = 2\n",
      "Sample 379: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/ztHoEQYDLDo_30.0-40.0.wav', Class ID = 3\n",
      "Sample 380: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0hz1GISR2tI_30.0-40.0.wav', Class ID = 2\n",
      "Sample 381: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/0VwX92X3iPc_30.0-40.0.wav', Class ID = 1\n",
      "Sample 382: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/0MFnZp9J0G0_0.0-10.0.wav', Class ID = 1\n",
      "Sample 383: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/Ac7aN4CgQPY_12.0-22.0.wav', Class ID = 3\n",
      "Sample 384: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/9d5q16pnFZM_30.0-40.0.wav', Class ID = 1\n",
      "Sample 385: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/15.wav', Class ID = 4\n",
      "Sample 386: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/8oTTgXIO0-I_90.0-100.0.wav', Class ID = 0\n",
      "Sample 387: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/AGyxlgx7DFU_0.0-10.0.wav', Class ID = 0\n",
      "Sample 388: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/50ZxQpgCccA_0.0-6.0.wav', Class ID = 0\n",
      "Sample 389: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/OFcr0uRNRjE_2.0-12.0.wav', Class ID = 3\n",
      "Sample 390: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/7K4kLUy6Kqo_0.0-10.0.wav', Class ID = 0\n",
      "Sample 391: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-XFBT5iAA44_0.0-10.0.wav', Class ID = 1\n",
      "Sample 392: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/06kaFCdYJ3U_0.0-10.0.wav', Class ID = 2\n",
      "Sample 393: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/YEqEve-tYPQ_0.0-7.0.wav', Class ID = 3\n",
      "Sample 394: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1o6y6ssTCgU_170.0-180.0.wav', Class ID = 0\n",
      "Sample 395: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/9.wav', Class ID = 4\n",
      "Sample 396: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/AjL9vvmfSsw_0.0-10.0.wav', Class ID = 0\n",
      "Sample 397: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1gr_BhwBB6o_30.0-40.0.wav', Class ID = 0\n",
      "Sample 398: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/GjE29zDIcf8_2.0-12.0.wav', Class ID = 3\n",
      "Sample 399: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-yvcu2zXj54_310.0-320.0.wav', Class ID = 0\n",
      "Sample 400: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/6.wav', Class ID = 4\n",
      "Sample 401: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-_yJyaRC1FU_0.0-10.0.wav', Class ID = 1\n",
      "Sample 402: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/IHvYchUsz_M_230.0-240.0.wav', Class ID = 3\n",
      "Sample 403: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/1et9yT2BYD0_30.0-40.0.wav', Class ID = 1\n",
      "Sample 404: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-6v3UBTptAs_20.0-30.0.wav', Class ID = 0\n",
      "Sample 405: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/F4VFJs2TuXg_130.0-140.0.wav', Class ID = 3\n",
      "Sample 406: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-yOS4BHAbwA_230.0-240.0.wav', Class ID = 1\n",
      "Sample 407: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1rIGVjzpPmU_0.0-3.0.wav', Class ID = 2\n",
      "Sample 408: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1IMi7yfZVVM_40.0-50.0.wav', Class ID = 2\n",
      "Sample 409: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/16.wav', Class ID = 4\n",
      "Sample 410: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/Z2wRcjWuSu4_0.0-8.0.wav', Class ID = 3\n",
      "Sample 411: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/4IJJtD4eRPA_0.0-10.0.wav', Class ID = 0\n",
      "Sample 412: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0q-80dzp6PU_60.0-70.0.wav', Class ID = 2\n",
      "Sample 413: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/09aRpEfUxT0_30.0-40.0.wav', Class ID = 0\n",
      "Sample 414: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1f6pK2x8T1s_30.0-40.0.wav', Class ID = 0\n",
      "Sample 415: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/0jaaX-we-8g_0.0-10.0.wav', Class ID = 0\n",
      "Sample 416: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/6liq2ueoVMM_0.0-10.0.wav', Class ID = 1\n",
      "Sample 417: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/-RMHRmd5utQ_0.0-10.0.wav', Class ID = 3\n",
      "Sample 418: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/F9jvnh-dKDI_0.0-10.0.wav', Class ID = 3\n",
      "Sample 419: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/4q-eGdrqiIw_30.0-40.0.wav', Class ID = 1\n",
      "Sample 420: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-YHjKxdA84c_530.0-540.0.wav', Class ID = 0\n",
      "Sample 421: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/3X4t1yXiR64_0.0-7.0.wav', Class ID = 0\n",
      "Sample 422: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-FzC6wlML8I_60.0-70.0.wav', Class ID = 1\n",
      "Sample 423: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/4MEa_7PkoUo_6.0-16.0.wav', Class ID = 1\n",
      "Sample 424: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/15htpcg-ii4_230.0-240.0.wav', Class ID = 0\n",
      "Sample 425: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/7R3tP8wKBsg_40.0-50.0.wav', Class ID = 0\n",
      "Sample 426: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/6gOjRqlgk_Y_30.0-40.0.wav', Class ID = 0\n",
      "Sample 427: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-SZhGRZZZT4_60.0-70.0.wav', Class ID = 1\n",
      "Sample 428: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/wU_LR9I9ea4_0.0-10.0.wav', Class ID = 1\n",
      "Sample 429: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-J0H5ah1G7A_30.0-40.0.wav', Class ID = 2\n",
      "Sample 430: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/NFmqHDRAkO0_10.0-20.0.wav', Class ID = 3\n",
      "Sample 431: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/1eW-T6vtO7k_100.0-110.0.wav', Class ID = 1\n",
      "Sample 432: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/-ZjxdgyIxoU_0.0-10.0.wav', Class ID = 3\n",
      "Sample 433: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/6e0F1Y6aMZk_30.0-40.0.wav', Class ID = 0\n",
      "Sample 434: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-Zb0rFhE3yo_160.0-170.0.wav', Class ID = 1\n",
      "Sample 435: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/VcD4ezit_sM_0.0-2.0.wav', Class ID = 3\n",
      "Sample 436: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/13.wav', Class ID = 4\n",
      "Sample 437: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/E3vTzyD-qXA_0.0-10.0.wav', Class ID = 3\n",
      "Sample 438: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/036-MR7EsZI_0.0-10.0.wav', Class ID = 1\n",
      "Sample 439: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/GlM4lg4k1_o_0.0-10.0.wav', Class ID = 3\n",
      "Sample 440: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/L9OTnZI9gYo_30.0-40.0.wav', Class ID = 3\n",
      "Sample 441: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/-VFMRxClr94_0.0-10.0.wav', Class ID = 3\n",
      "Sample 442: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/2.wav', Class ID = 4\n",
      "Sample 443: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/HPgo8LJzfaw_0.0-10.0.wav', Class ID = 3\n",
      "Sample 444: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/10mtAupS0I4_0.0-10.0.wav', Class ID = 0\n",
      "Sample 445: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-7ye24UFRng_0.0-10.0.wav', Class ID = 2\n",
      "Sample 446: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/76pFWYirLCw_0.0-10.0.wav', Class ID = 0\n",
      "Sample 447: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/1.wav', Class ID = 4\n",
      "Sample 448: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-lUCohWH9xg_29.0-39.0.wav', Class ID = 2\n",
      "Sample 449: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/XoROmqUNjck_0.0-10.0.wav', Class ID = 3\n",
      "Sample 450: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-2m0EljzvK0_190.0-200.0.wav', Class ID = 0\n",
      "Sample 451: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-jpbCWcz2pk_30.0-40.0.wav', Class ID = 2\n",
      "Sample 452: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/FwI80MBPzeA_0.0-10.0.wav', Class ID = 3\n",
      "Sample 453: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1eI2-vhs0YY_21.0-31.0.wav', Class ID = 0\n",
      "Sample 454: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/X83qvgYnmOM_0.0-10.0.wav', Class ID = 0\n",
      "Sample 455: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/04q2Ozr-WYA_0.0-10.0.wav', Class ID = 1\n",
      "Sample 456: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1M-zH_FQDdM_30.0-40.0.wav', Class ID = 0\n",
      "Sample 457: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/1Is1xfDjZrw_30.0-40.0.wav', Class ID = 0\n",
      "Sample 458: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/17BqM45nQxI_50.0-60.0.wav', Class ID = 0\n",
      "Sample 459: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/82EHZ4_pTps_30.0-40.0.wav', Class ID = 0\n",
      "Sample 460: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/KwtmADJzwGY_0.0-10.0.wav', Class ID = 3\n",
      "Sample 461: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/4QSUv_YkNII_30.0-40.0.wav', Class ID = 0\n",
      "Sample 462: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/mcNmtHjbjew_0.0-9.0.wav', Class ID = 3\n",
      "Sample 463: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/-4NLarMj4xU_30.0-40.0.wav', Class ID = 2\n",
      "Sample 464: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/ICCqtTMm02g_30.0-40.0.wav', Class ID = 3\n",
      "Sample 465: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/DOUfEmpCH_A_40.0-50.0.wav', Class ID = 3\n",
      "Sample 466: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/0H2uMhzSitY_520.0-530.0.wav', Class ID = 2\n",
      "Sample 467: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/01hjVJN9xCg_30.0-40.0.wav', Class ID = 2\n",
      "Sample 468: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-z0q4AgXQwo_30.0-40.0.wav', Class ID = 0\n",
      "Sample 469: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/075SHAj6J3Y_30.0-40.0.wav', Class ID = 2\n",
      "Sample 470: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/ASfZSrB3ttk_0.0-10.0.wav', Class ID = 0\n",
      "Sample 471: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/-RRi3QktLdc_500.0-510.0.wav', Class ID = 0\n",
      "Sample 472: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/CcTsUNQqF4k_0.0-10.0.wav', Class ID = 3\n",
      "Sample 473: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/7feRrqB4AvM_60.0-70.0.wav', Class ID = 0\n",
      "Sample 474: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/26owMAFMWJw_0.0-8.0.wav', Class ID = 1\n",
      "Sample 475: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-_6ZGvSbXYc_6.0-16.0.wav', Class ID = 1\n",
      "Sample 476: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/JBgtz6f5jc8_40.0-50.0.wav', Class ID = 3\n",
      "Sample 477: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Silence/-m7GnVjjabs_0.0-10.0.wav', Class ID = 1\n",
      "Sample 478: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/29.wav', Class ID = 4\n",
      "Sample 479: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Beep/P91FJWTNkQ8_0.0-7.0.wav', Class ID = 3\n",
      "Sample 480: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/676jJ4ro9J8_40.0-50.0.wav', Class ID = 0\n",
      "Sample 481: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/8rS14kaupdE_0.0-10.0.wav', Class ID = 0\n",
      "Sample 482: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Robot_moving/21.wav', Class ID = 4\n",
      "Sample 483: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Speech/9zmQwBUFwd4_0.0-10.0.wav', Class ID = 0\n",
      "Sample 484: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/train/Music/1ObHezZoZ1I_210.0-220.0.wav', Class ID = 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filenames = filtered_df['filename'].tolist()\n",
    "targets = filtered_df['class_id'].tolist()\n",
    "\n",
    "main_ds = tf.data.Dataset.from_tensor_slices((filenames, targets))\n",
    "main_ds=main_ds.shuffle(buffer_size=1000)\n",
    "\n",
    "# Function to print dataset labels\n",
    "def print_dataset_labels(dataset, num_samples=500):\n",
    "    for i, (filename, target) in enumerate(dataset.take(num_samples)):\n",
    "\n",
    "            print(f\"Sample {i+1}: Filename = {filename.numpy()}, Class ID = {target.numpy()}\")\n",
    "        \n",
    "print_dataset_labels(main_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_wav_for_map(filename, label):\n",
    "  return load_wav_16k_mono(filename), label\n",
    "\n",
    "main_ds = main_ds.map(load_wav_for_map)\n",
    "main_ds.element_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(1024,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applies the embedding extraction model to a wav data\n",
    "def extract_embedding(wav_data, label):\n",
    "  ''' run YAMNet to extract embedding from the wav data '''\n",
    "  scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
    "  num_embeddings = tf.shape(embeddings)[0]\n",
    "  return (embeddings,\n",
    "            tf.repeat(label, num_embeddings))\n",
    "            \n",
    "\n",
    "# extract embedding\n",
    "main_ds = main_ds.map(extract_embedding).unbatch()\n",
    "main_ds.element_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: (TensorSpec(shape=(1024,), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))\n",
      "Validation dataset: (TensorSpec(shape=(1024,), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Shuffle the dataset\n",
    "shuffled_ds = main_ds.shuffle(buffer_size=len(filenames), reshuffle_each_iteration=False)\n",
    "\n",
    "# Define the split proportions\n",
    "train_size = int(0.8 * len(filenames))\n",
    "val_size = int(0.1 * len(filenames))\n",
    "test_size = int(0.1 * len(filenames))\n",
    "\n",
    "# Split the dataset\n",
    "train_ds = shuffled_ds.take(train_size)\n",
    "remaining_ds = shuffled_ds.skip(train_size)\n",
    "val_ds = remaining_ds.take(val_size)\n",
    "remaining_ds = shuffled_ds.skip(val_size)\n",
    "test_ds=val_ds = remaining_ds.take(val_size)\n",
    "\n",
    "# Print dataset specs for verification\n",
    "print(\"Train dataset:\", train_ds.element_spec)\n",
    "print(\"Validation dataset:\", val_ds.element_spec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.io_ops.read_file(filename, name=None)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE).repeat()\n",
    "val_ds = val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "tf.io.read_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"my_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,565</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m524,800\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                       \u001b[38;5;34m2,565\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">527,365</span> (2.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m527,365\u001b[0m (2.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">527,365</span> (2.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m527,365\u001b[0m (2.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1024,), dtype=tf.float32,\n",
    "                          name='input_embedding'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(my_classes))\n",
    "], name='my_model')\n",
    "\n",
    "my_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                            patience=3,\n",
    "                                            restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.8313 - loss: 0.7021 - val_accuracy: 0.4167 - val_loss: 2.4309\n",
      "Epoch 2/20\n",
      "\u001b[1m  8/400\u001b[0m \u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9557 - loss: 0.1753"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 13:27:54.548146: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9384 - loss: 0.2381 - val_accuracy: 0.4792 - val_loss: 2.1200\n",
      "Epoch 3/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9442 - loss: 0.1205 - val_accuracy: 0.4167 - val_loss: 2.4566\n",
      "Epoch 4/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9419 - loss: 0.1097 - val_accuracy: 0.4167 - val_loss: 2.5826\n",
      "Epoch 5/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9431 - loss: 0.1164 - val_accuracy: 0.4167 - val_loss: 2.6718\n",
      "Epoch 6/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9430 - loss: 0.1042 - val_accuracy: 0.4375 - val_loss: 2.7754\n",
      "Epoch 7/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9446 - loss: 0.1041 - val_accuracy: 0.4167 - val_loss: 2.9992\n",
      "Epoch 8/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9435 - loss: 0.1043 - val_accuracy: 0.4167 - val_loss: 3.1628\n",
      "Epoch 9/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9455 - loss: 0.1015 - val_accuracy: 0.4167 - val_loss: 3.1642\n",
      "Epoch 10/20\n",
      "\u001b[1m 14/400\u001b[0m \u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9592 - loss: 0.0827  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 13:28:36.281645: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9462 - loss: 0.0984 - val_accuracy: 0.4167 - val_loss: 3.2361\n",
      "Epoch 11/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9459 - loss: 0.1001 - val_accuracy: 0.4375 - val_loss: 3.2910\n",
      "Epoch 12/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9498 - loss: 0.0954 - val_accuracy: 0.4375 - val_loss: 3.3417\n",
      "Epoch 13/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9487 - loss: 0.0983 - val_accuracy: 0.4375 - val_loss: 3.4060\n",
      "Epoch 14/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9452 - loss: 0.1001 - val_accuracy: 0.5000 - val_loss: 3.3973\n",
      "Epoch 15/20\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9471 - loss: 0.0983 - val_accuracy: 0.4375 - val_loss: 3.4991\n"
     ]
    }
   ],
   "source": [
    "history = my_model.fit(train_ds,\n",
    "                       epochs=20,\n",
    "                       steps_per_epoch=400,\n",
    "                       validation_data=val_ds,\n",
    "                       callbacks=callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function load_wav_16k_mono at 0x7740466b9990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function load_wav_16k_mono at 0x7740466b9990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "wav=load_wav_16k_mono('/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/-v5tNN6YADM_0.0-10.0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My model :The main sound is: Speech\n"
     ]
    }
   ],
   "source": [
    "scores, embeddings, spectrogram = yamnet_model(wav)\n",
    "result = my_model(embeddings).numpy()\n",
    "\n",
    "inferred_class = my_classes[result.mean(axis=0).argmax()]\n",
    "print(f'My model :The main sound is: {inferred_class}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.5671134,  3.3958538, -3.763562 , -6.002507 ,  4.0054936],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yamnet : The main sound is: Silence\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores, embeddings, spectrogram = yamnet_model(wav)\n",
    "class_scores = tf.reduce_mean(scores, axis=0)\n",
    "top_class = tf.argmax(class_scores)\n",
    "inferred_class = class_names[top_class]\n",
    "\n",
    "print(f'Yamnet : The main sound is: {inferred_class}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enregistrer un modle qui peut directement prendre un fichier WAV en entre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReduceMeanLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, axis=0, **kwargs):\n",
    "    super(ReduceMeanLayer, self).__init__(**kwargs)\n",
    "    self.axis = axis\n",
    "\n",
    "  def call(self, input):\n",
    "    return tf.math.reduce_mean(input, axis=self.axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'yamnet' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=float32, sparse=None, name=audio>,) and kwargs: {} for signature: (waveform: TensorSpec(shape=(None,), dtype=tf.float32, name=None)).\n\nCall arguments received by layer 'yamnet' (type KerasLayer):\n   inputs=<KerasTensor shape=(None,), dtype=float32, sparse=None, name=audio>\n   training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17899/4193897353.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m embedding_extraction_layer = hub.KerasLayer(yamnet_model_handle,\n\u001b[1;32m      5\u001b[0m                                             trainable=False, name='yamnet')\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_extraction_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mserving_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mserving_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceMeanLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserving_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;31m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_training_argument\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer 'yamnet' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=float32, sparse=None, name=audio>,) and kwargs: {} for signature: (waveform: TensorSpec(shape=(None,), dtype=tf.float32, name=None)).\n\nCall arguments received by layer 'yamnet' (type KerasLayer):\n   inputs=<KerasTensor shape=(None,), dtype=float32, sparse=None, name=audio>\n   training=None"
     ]
    }
   ],
   "source": [
    "saved_model_path = './pleasesave'\n",
    "\n",
    "input_segment = tf.keras.layers.Input(shape=(), dtype=tf.float32, name='audio')\n",
    "embedding_extraction_layer = hub.KerasLayer(yamnet_model_handle,\n",
    "                                            trainable=False, name='yamnet')\n",
    "_, embeddings_output, _ = embedding_extraction_layer(input_segment)\n",
    "serving_outputs = my_model(embeddings_output)\n",
    "serving_outputs = ReduceMeanLayer(axis=0, name='classifier')(serving_outputs)\n",
    "serving_model = tf.keras.Model(input_segment, serving_outputs)\n",
    "serving_model.save(saved_model_path, include_optimizer=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the path where the final model will be saved\n",
    "saved_model_path = './pleasesave/hahaha123.keras'\n",
    "\n",
    "# Load the YAMNet model\n",
    "\n",
    "\n",
    "# Define the input tensor spec (audio waveform)\n",
    "inpu_segment = tf.keras.Input(shape=(), dtype=tf.float32, name='audio_input')\n",
    "\n",
    "# Wrap the YAMNet model call in a Lambda layer\n",
    "embeddings_output = tf.keras.layers.Lambda(lambda x: yamnet_model(x)[1,name='extraction'])(inpu_segment)\n",
    "\n",
    "# Pass the embeddings to your custom classification model\n",
    "serving_outputs = my_model(embeddings_output)\n",
    "\n",
    "# Apply a ReduceMean layer to aggregate the outputs (if needed)\n",
    "serving_outputs = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=0), name='5_class_classifier')(serving_outputs)\n",
    "\n",
    "# Create the final model\n",
    "serving_model = tf.keras.Model(inputs=inpu_segment, outputs=serving_outputs)\n",
    "\n",
    "# Save the model as a SavedModel\n",
    "serving_model.save(saved_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(serving_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Load the YAMNet model from TensorFlow Hub or your saved model path\n",
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'  # or use your saved model path\n",
    "yamnet_model = hub.KerasLayer(yamnet_model_handle, trainable=False, name='yamnet')\n",
    "\n",
    "# Define the input tensor spec (audio waveform)\n",
    "input_segment = tf.keras.Input(shape=(None,), dtype=tf.float32, name='audio_input')\n",
    "\n",
    "# Wrap the YAMNet model call in a Lambda layer with explicit output shape\n",
    "def extract_embeddings(x):\n",
    "    _, embeddings, _ = yamnet_model(x)\n",
    "    return embeddings\n",
    "\n",
    "embeddings_output = tf.keras.layers.Lambda(\n",
    "    lambda x: extract_embeddings(x),\n",
    "    output_shape=(1024,),  # Specify the output shape of the embeddings\n",
    "    name='embeddings_output'\n",
    ")(input_segment)\n",
    "\n",
    "# Load or define your custom classification model\n",
    "# For this example, I'll assume `my_model` is a simple dense network\n",
    "\n",
    "\n",
    "# Pass the embeddings to your custom classification model\n",
    "serving_outputs = my_model(embeddings_output)\n",
    "\n",
    "# Apply a ReduceMean layer to aggregate the outputs (if needed)\n",
    "serving_outputs = tf.keras.layers.Lambda(\n",
    "    lambda x: tf.reduce_mean(x, axis=0),\n",
    "    name='5_class_classifier'\n",
    ")(serving_outputs)\n",
    "\n",
    "# Create the final model\n",
    "serving_model = tf.keras.Model(inputs=input_segment, outputs=serving_outputs)\n",
    "\n",
    "# Define the path where the final model will be saved\n",
    "saved_model_path = './pleasesave/hahaha123.keras'\n",
    "\n",
    "# Save the model as a SavedModel\n",
    "serving_model.save(saved_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tried to export a function which references an 'untracked' resource. TensorFlow objects (e.g. tf.Variable) captured by functions must be 'tracked' by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly. See the information below:\n\tFunction name = b'__inference_signature_wrapper_serving_default_334025'\n\tCaptured Tensor = <ResourceHandle(name=\"layer1/conv/kernel/730\", device=\"/job:localhost/replica:0/task:0/device:CPU:0\", container=\"Anonymous\", type=\"tensorflow::Var\", dtype and shapes : \"[ DType enum: 1, Shape: [3,3,1,32] ]\")>\n\tTrackable referencing this tensor = <tf.Variable 'layer1/conv/kernel:0' shape=(3, 3, 1, 32) dtype=float32>\n\tInternal Tensor = Tensor(\"333741:0\", shape=(), dtype=resource)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17899/1733167032.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Save the model as a TensorFlow SavedModel folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserving_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model_folder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1430\u001b[0m   \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementWriteApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SAVE_V2_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m   \u001b[0msave_and_return_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementWrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[0;32m-> 1467\u001b[0;31m       _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0m\u001b[1;32m   1468\u001b[0m   saved_model.saved_model_schema_version = (\n\u001b[1;32m   1469\u001b[0m       constants.SAVED_MODEL_SCHEMA_VERSION)\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_meta_graph_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1604\u001b[0m   \u001b[0msaveable_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SaveableView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_graph_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m   \u001b[0mobject_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_graph_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1606\u001b[0;31m   asset_info, exported_graph = _fill_meta_graph_def(\n\u001b[0m\u001b[1;32m   1607\u001b[0m       \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m       \u001b[0msaveable_view\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msaveable_view\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_fill_meta_graph_def\u001b[0;34m(meta_graph_def, saveable_view, signature_functions, namespace_whitelist, save_custom_gradients, create_saver, enable_debug_stripper, defaults)\u001b[0m\n\u001b[1;32m    968\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mexported_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0mobject_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masset_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m     \u001b[0msignatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_generate_signatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msave_custom_gradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;31m# Custom gradients functions must be traced in the same context as the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_generate_signatures\u001b[0;34m(signature_functions, object_map, defaults)\u001b[0m\n\u001b[1;32m    652\u001b[0m         sorted(\n\u001b[1;32m    653\u001b[0m             object_map[function].function.structured_input_signature[1].keys()))\n\u001b[0;32m--> 654\u001b[0;31m     outputs = object_map[function](**{\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0mkwarg_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmapped_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkwarg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapped_input\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwarg_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapped_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/saved_model_exported_concrete.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mbound_arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     )\n\u001b[0;32m---> 45\u001b[0;31m     export_captures = _map_captures_to_created_tensors(\n\u001b[0m\u001b[1;32m     46\u001b[0m         self.function.graph.captures, self.tensor_map, self.function)\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_captures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/saved_model_exported_concrete.py\u001b[0m in \u001b[0;36m_map_captures_to_created_tensors\u001b[0;34m(original_captures, tensor_map, function)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mmapped_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmapped_resource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m       \u001b[0m_raise_untracked_capture_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mexport_captures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexport_captures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/saved_model_exported_concrete.py\u001b[0m in \u001b[0;36m_raise_untracked_capture_error\u001b[0;34m(function_name, capture, internal_capture, node_path)\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minternal_capture\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\\n\\tInternal Tensor = {internal_capture}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tried to export a function which references an 'untracked' resource. TensorFlow objects (e.g. tf.Variable) captured by functions must be 'tracked' by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly. See the information below:\n\tFunction name = b'__inference_signature_wrapper_serving_default_334025'\n\tCaptured Tensor = <ResourceHandle(name=\"layer1/conv/kernel/730\", device=\"/job:localhost/replica:0/task:0/device:CPU:0\", container=\"Anonymous\", type=\"tensorflow::Var\", dtype and shapes : \"[ DType enum: 1, Shape: [3,3,1,32] ]\")>\n\tTrackable referencing this tensor = <tf.Variable 'layer1/conv/kernel:0' shape=(3, 3, 1, 32) dtype=float32>\n\tInternal Tensor = Tensor(\"333741:0\", shape=(), dtype=resource)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the path where the model will be saved as a folder\n",
    "saved_model_folder_path = '/home/focus/Bureau/Audio_Node/src/resources/ray_audio/saving_costum_yamnet'\n",
    "\n",
    "# Adjust input shape according to the model's expected input\n",
    "input_segment = tf.keras.Input(shape=(), dtype=tf.float32, name='audio_input')\n",
    "\n",
    "# Define the YAMNet model's embedding extraction layer (Ensure correct shape and layer configurations)\n",
    "def extract_embeddings(x):\n",
    "    return yamnet_model(x)[1]  # Assuming this extracts the embedding\n",
    "\n",
    "embeddings_output = tf.keras.layers.Lambda(\n",
    "    extract_embeddings, \n",
    "    output_shape=(1024,),  # Adjust this according to actual embeddings output\n",
    "    name='embeddings_output'\n",
    ")(input_segment)\n",
    "\n",
    "# Pass the embeddings to your custom classification model\n",
    "serving_outputs = my_model(embeddings_output)\n",
    "\n",
    "# Apply a ReduceMean layer to aggregate the outputs (if needed)\n",
    "serving_outputs = tf.keras.layers.Lambda(\n",
    "    lambda x: tf.reduce_mean(x, axis=0),\n",
    "    name='5_class_classifier'\n",
    ")(serving_outputs)\n",
    "\n",
    "# Create the final model\n",
    "serving_model = tf.keras.Model(inputs=input_segment, outputs=serving_outputs)\n",
    "\n",
    "# Save the model as a TensorFlow SavedModel folder\n",
    "tf.saved_model.save(serving_model, saved_model_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "in user code:\n\n    File \"/home/focus/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/layer.py\", line 120, in serving_default  *\n        return self(inputs)\n    File \"/home/focus/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/focus/.local/lib/python3.10/site-packages/keras/src/ops/function.py\", line 179, in _run_through_graph\n        output_tensors.append(tensor_dict[id(x)])\n\n    KeyError: 'Exception encountered when calling Functional.call().\\n\\n\\x1b[1m131117707213168\\x1b[0m\\n\\nArguments received by Functional.call():\\n   inputs=tf.Tensor(shape=(None,), dtype=float32)\\n   training=None\\n   mask=None'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17899/3282754734.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mserving_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_segment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserving_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#serving_model.save(saved_model_path, include_optimizer=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserving_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1430\u001b[0m   \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementWriteApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SAVE_V2_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m   \u001b[0msave_and_return_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementWrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[0;32m-> 1467\u001b[0;31m       _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0m\u001b[1;32m   1468\u001b[0m   saved_model.saved_model_schema_version = (\n\u001b[1;32m   1469\u001b[0m       constants.SAVED_MODEL_SCHEMA_VERSION)\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_meta_graph_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1590\u001b[0m   \u001b[0maugmented_graph_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_AugmentedGraphView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msignatures\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m     signatures = signature_serialization.find_function_to_export(\n\u001b[0m\u001b[1;32m   1593\u001b[0m         \u001b[0maugmented_graph_view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m     )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/signature_serialization.py\u001b[0m in \u001b[0;36mfind_function_to_export\u001b[0;34m(saveable_view)\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0;31m# serving that model way later in the process stops working.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0mpossible_signatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdef_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConcreteFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36mlist_children\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    188\u001b[0m       \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m       for name, child in super(_AugmentedGraphView, self).list_children(\n\u001b[0m\u001b[1;32m    191\u001b[0m           \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m           \u001b[0msave_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaveType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVEDMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/checkpoint/graph_view.py\u001b[0m in \u001b[0;36mlist_children\u001b[0;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m     \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     for name, ref in super(ObjectGraphView,\n\u001b[0m\u001b[1;32m     76\u001b[0m                            self).children(obj, save_type, **kwargs).items():\n\u001b[1;32m     77\u001b[0m       \u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableReference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/checkpoint/trackable_view.py\u001b[0m in \u001b[0;36mchildren\u001b[0;34m(cls, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m       \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/layer.py\u001b[0m in \u001b[0;36m_trackable_children\u001b[0;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msave_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"savedmodel\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/trackable/autotrackable.py\u001b[0m in \u001b[0;36m_trackable_children\u001b[0;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdef_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_all_concrete_functions_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# Additional dependencies may have been generated during function tracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_list_all_concrete_functions_for_serialization\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[0mconcrete_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen_signatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m       \u001b[0mconcrete_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1249\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;31m# Implements PolymorphicFunction.get_concrete_function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/layer.py\u001b[0m in \u001b[0;36mtf__serving_default\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/ops/function.py\u001b[0m in \u001b[0;36m_run_through_graph\u001b[0;34m(self, inputs, operation_fn, call_fn)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: in user code:\n\n    File \"/home/focus/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/layer.py\", line 120, in serving_default  *\n        return self(inputs)\n    File \"/home/focus/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/focus/.local/lib/python3.10/site-packages/keras/src/ops/function.py\", line 179, in _run_through_graph\n        output_tensors.append(tensor_dict[id(x)])\n\n    KeyError: 'Exception encountered when calling Functional.call().\\n\\n\\x1b[1m131117707213168\\x1b[0m\\n\\nArguments received by Functional.call():\\n   inputs=tf.Tensor(shape=(None,), dtype=float32)\\n   training=None\\n   mask=None'\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = '/home/focus/Bureau/Audio_Node/src/resources/ray_audio/saving_costum_yamnet/'\n",
    "\n",
    "input_segment = tf.keras.layers.Input(shape=(), dtype=tf.float32, name='audio')\n",
    "#embedding_extraction_layer = hub.KerasLayer(yamnet_model,\n",
    "                                            #trainable=False, name='yamnet')\n",
    "#embeddings_output = embedding_extraction_layer(input_segment)[1]\n",
    "serving_outputs = my_model(embeddings_output)\n",
    "serving_outputs = ReduceMeanLayer(axis=0, name='classifier')(serving_outputs)\n",
    "serving_model = tf.keras.Model(input_segment, serving_outputs)\n",
    "#serving_model.save(saved_model_path, include_optimizer=False)\n",
    "tf.saved_model.save(serving_model, saved_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model=keras.layers.TFSMLayer('/home/focus/Bureau/Audio_Node/src/resources/ray_audio/trained_custom_5classes', call_endpoint='serving_default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.src.export.export_lib.TFSMLayer"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reloaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "wav=load_wav_16k_mono('/home/focus/Bureau/Audio_Node/src/resources/ray_audio/test_wav/music.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classes = ['Speech', 'Silence', 'Music', 'Beep', 'Robot_moving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predicted class is Speech\n"
     ]
    }
   ],
   "source": [
    "result=reloaded_model(wav)\n",
    "prediction=my_classes[tf.argmax(result['output_0'])]\n",
    "print(f'the predicted class is {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(137435, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print((tf.argmin(wav)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real time prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.000000e+00  0.000000e+00  0.000000e+00 ...  3.051851e-05 -3.051851e-05\n",
      " -9.155553e-05]\n",
      "The main sound is: Robot_moving\n",
      "[-1.8311106e-04 -2.1362957e-04 -1.8311106e-04 ... -9.1555528e-05\n",
      " -3.0518509e-05 -3.0518509e-05]\n",
      "The main sound is: Speech\n",
      "[3.0518509e-05 1.2207404e-04 1.5259255e-04 ... 0.0000000e+00 9.1555528e-05\n",
      " 9.1555528e-05]\n",
      "The main sound is: Speech\n",
      "[ 0.0000000e+00 -9.1555528e-05 -1.5259255e-04 ... -1.5259255e-04\n",
      " -2.4414808e-04 -3.3570360e-04]\n",
      "The main sound is: Speech\n",
      "[-0.00018311 -0.00021363 -0.0003357  ... -0.00015259 -0.00042726\n",
      " -0.00042726]\n",
      "The main sound is: Speech\n",
      "[-3.3570360e-04 -3.9674062e-04 -3.3570360e-04 ...  1.8311106e-04\n",
      "  6.1037019e-05 -1.8311106e-04]\n",
      "The main sound is: Speech\n",
      "[-3.9674062e-04 -3.6622211e-04 -2.7466659e-04 ... -2.4414808e-04\n",
      " -1.8311106e-04  3.0518509e-05]\n",
      "The main sound is: Speech\n",
      "[-6.1037019e-05 -2.4414808e-04 -4.2725913e-04 ... -1.2207404e-04\n",
      " -1.5259255e-04 -9.1555528e-05]\n",
      "The main sound is: Speech\n",
      "[-3.0518509e-05  3.0518509e-05  1.8311106e-04 ... -3.0518509e-05\n",
      "  0.0000000e+00  3.0518509e-05]\n",
      "The main sound is: Speech\n",
      "[-9.1555528e-05 -1.8311106e-04 -2.4414808e-04 ... -3.6622211e-04\n",
      " -2.4414808e-04 -3.0518509e-05]\n",
      "The main sound is: Speech\n",
      "[ 9.155553e-05  3.051851e-05 -3.051851e-05 ...  9.155553e-05 -6.103702e-05\n",
      " -3.051851e-05]\n",
      "The main sound is: Speech\n",
      "[ 9.1555528e-05  6.1037019e-05  6.1037019e-05 ... -1.2207404e-04\n",
      " -2.1362957e-04 -3.3570360e-04]\n",
      "The main sound is: Robot_moving\n",
      "[-0.00024415 -0.00036622 -0.00054933 ... -0.00021363 -0.00027467\n",
      " -0.00024415]\n",
      "The main sound is: Robot_moving\n",
      "[-0.00015259 -0.00024415 -0.0003357  ...  0.00079348  0.00067141\n",
      "  0.00085452]\n",
      "The main sound is: Robot_moving\n",
      "[ 1.0376293e-03  7.6296274e-04  6.1037019e-04 ... -1.2207404e-04\n",
      "  3.0518509e-05  3.6622211e-04]\n",
      "The main sound is: Speech\n",
      "[0.00018311 0.00024415 0.00039674 ... 0.0216071  0.01919614 0.01605274]\n",
      "The main sound is: Speech\n",
      "[0.01178014 0.00704978 0.00357067 ... 0.00390637 0.00469985 0.00491348]\n",
      "The main sound is: Speech\n",
      "[0.00463881 0.00427259 0.00375378 ... 0.00421155 0.0044557  0.00503555]\n",
      "The main sound is: Speech\n",
      "[ 6.225776e-03  7.812738e-03  8.697775e-03 ...  3.051851e-05  0.000000e+00\n",
      " -6.103702e-04]\n",
      "The main sound is: Speech\n",
      "[-8.5451826e-04 -3.3570360e-04 -6.1037019e-05 ... -2.7466659e-04\n",
      " -1.2207404e-04 -9.1555528e-05]\n",
      "The main sound is: Speech\n",
      "[-0.00024415 -0.00021363 -0.00021363 ... -0.00064089 -0.00067141\n",
      " -0.00067141]\n",
      "The main sound is: Speech\n",
      "[-7.6296274e-04 -6.7140721e-04 -9.1555528e-04 ... -1.2207404e-04\n",
      " -6.1037019e-05  0.0000000e+00]\n",
      "The main sound is: Robot_moving\n",
      "[-3.0518509e-05  2.1362957e-04  3.9674062e-04 ...  3.6622211e-04\n",
      "  5.4933317e-04  4.2725913e-04]\n",
      "The main sound is: Robot_moving\n",
      "[ 3.0518509e-04  3.0518509e-05 -1.2207404e-04 ... -2.0447401e-03\n",
      " -1.3122959e-03 -1.2207404e-03]\n",
      "The main sound is: Robot_moving\n",
      "[-0.00140385 -0.00061037 -0.00137333 ...  0.00054933  0.00067141\n",
      " -0.00180059]\n",
      "The main sound is: Speech\n",
      "[-0.00192267 -0.00173956 -0.0021363  ... -0.00146489 -0.0019837\n",
      " -0.00128178]\n",
      "The main sound is: Speech\n",
      "[-0.00094607 -0.00122074 -0.0011597  ...  0.          0.00036622\n",
      "  0.00042726]\n",
      "The main sound is: Speech\n",
      "[0.00097659 0.00140385 0.00079348 ... 0.00021363 0.00027467 0.        ]\n",
      "The main sound is: Speech\n",
      "[-0.00042726 -0.00027467 -0.00054933 ... -0.00824    -0.00735496\n",
      " -0.00616474]\n",
      "The main sound is: Speech\n",
      "[-0.00488296 -0.00341807 -0.00216681 ... -0.00769066 -0.00894192\n",
      " -0.01049837]\n",
      "The main sound is: Speech\n",
      "[-0.01202429 -0.01037629 -0.00753807 ...  0.00863674  0.00689718\n",
      "  0.00302133]\n",
      "The main sound is: Speech\n",
      "[ 0.00076296 -0.00341807 -0.00994903 ...  0.0146794   0.01562548\n",
      "  0.01461837]\n",
      "The main sound is: Beep\n",
      "[0.014008   0.01525925 0.01538133 ... 0.00100711 0.00112918 0.00109867]\n",
      "The main sound is: Beep\n",
      "[ 1.2817774e-03  1.3122959e-03  1.3733329e-03 ... -6.1037019e-05\n",
      " -1.2207404e-04 -2.1362957e-04]\n",
      "The main sound is: Robot_moving\n",
      "[-9.1555528e-05  9.1555528e-05  6.1037019e-05 ... -1.5320292e-02\n",
      " -1.2634663e-02 -8.1484420e-03]\n",
      "The main sound is: Speech\n",
      "[-0.00234993  0.00387585  0.0097354  ...  0.01617481  0.01312296\n",
      "  0.00820948]\n",
      "The main sound is: Speech\n",
      "[ 0.00183111 -0.00469985 -0.0105594  ... -0.01663259 -0.01315348\n",
      " -0.00784326]\n",
      "The main sound is: Speech\n",
      "[-0.00097659  0.0061037   0.01211585 ...  0.04593036  0.03689688\n",
      "  0.02243111]\n",
      "The main sound is: Beep\n",
      "[ 0.00463881 -0.01409955 -0.03073214 ... -0.0089114  -0.00643941\n",
      " -0.00292978]\n",
      "The main sound is: Music\n",
      "[0.00109867 0.00491348 0.00814844 ... 0.00643941 0.00424207 0.00128178]\n",
      "The main sound is: Speech\n",
      "[-0.0019837  -0.00488296 -0.00698874 ... -0.01470992 -0.01080355\n",
      " -0.00518815]\n",
      "The main sound is: Speech\n",
      "[0.00137333 0.00759911 0.01260414 ... 0.00473037 0.00292978 0.000824  ]\n",
      "The main sound is: Music\n",
      "[-0.0013123  -0.00347911 -0.00524918 ... -0.02008118 -0.01440474\n",
      " -0.00631733]\n",
      "The main sound is: Speech\n",
      "[ 0.00259407  0.01086459  0.01770074 ... -0.00018311 -0.00036622\n",
      " -0.00036622]\n",
      "The main sound is: Silence\n",
      "[-0.00042726 -0.00039674 -0.00024415 ... -0.00057985 -0.00061037\n",
      " -0.00061037]\n",
      "The main sound is: Music\n",
      "[-4.8829615e-04 -5.4933317e-04 -6.4088870e-04 ...  3.0518509e-05\n",
      "  9.1555528e-05  1.2207404e-04]\n",
      "The main sound is: Speech\n",
      "[ 1.5259255e-04  9.1555528e-05 -3.0518509e-05 ...  6.1037019e-05\n",
      "  6.1037019e-05  1.2207404e-04]\n",
      "The main sound is: Speech\n",
      "[1.2207404e-04 9.1555528e-05 3.0518509e-05 ... 3.0518509e-04 3.3570360e-04\n",
      " 2.7466659e-04]\n",
      "The main sound is: Speech\n",
      "[ 2.4414808e-04  2.1362957e-04  6.1037019e-05 ... -1.5259255e-04\n",
      " -6.1037019e-05 -6.1037019e-05]\n",
      "The main sound is: Robot_moving\n",
      "[1.2207404e-04 6.1037019e-05 6.1037019e-05 ... 9.1555528e-05 6.1037019e-05\n",
      " 2.4414808e-04]\n",
      "The main sound is: Robot_moving\n",
      "[ 0.00045778  0.00054933  0.0003357  ... -0.01687674  0.01043733\n",
      "  0.03570666]\n",
      "The main sound is: Speech\n",
      "[ 0.05526902  0.06646931  0.06778161 ... -0.01263466 -0.03784295\n",
      " -0.05694754]\n",
      "The main sound is: Beep\n",
      "[-0.06750695 -0.06772057 -0.05749687 ...  0.01193274  0.01065096\n",
      "  0.00753807]\n",
      "The main sound is: Music\n",
      "[ 0.00332652 -0.0013123  -0.00592059 ... -0.01168859 -0.00460829\n",
      "  0.00314341]\n",
      "The main sound is: Speech\n",
      "[ 0.01040681  0.01626637  0.01944029 ...  0.01144444  0.00289926\n",
      " -0.00613422]\n",
      "The main sound is: Speech\n",
      "[-0.01425214 -0.02026429 -0.02313303 ... -0.00054933 -0.00045778\n",
      " -0.00042726]\n",
      "The main sound is: Beep\n",
      "[-8.5451826e-04 -8.5451826e-04 -4.8829615e-04 ... -3.0518509e-04\n",
      "  9.1555528e-05  4.2725913e-04]\n",
      "The main sound is: Speech\n",
      "[ 7.0192572e-04  9.4607379e-04  8.5451826e-04 ... -1.5259255e-04\n",
      " -6.1037019e-05 -6.1037019e-05]\n",
      "The main sound is: Speech\n",
      "[ 3.0518509e-05  3.0518509e-05 -3.0518509e-05 ... -1.8311106e-04\n",
      " -1.5259255e-04 -9.1555528e-05]\n",
      "The main sound is: Speech\n",
      "[-3.0518509e-05 -6.1037019e-05 -6.1037019e-05 ...  4.8829615e-04\n",
      "  1.8311106e-04 -5.1881466e-04]\n",
      "The main sound is: Robot_moving\n",
      "[-0.00015259  0.00045778 -0.00012207 ... -0.00067141 -0.00106815\n",
      "  0.00097659]\n",
      "The main sound is: Beep\n",
      "[ 3.1434065e-03 -5.4933317e-04 -1.3428144e-03 ... -1.5259255e-04\n",
      "  3.0518509e-05  8.8503677e-04]\n",
      "The main sound is: Robot_moving\n",
      "[-1.8311106e-04 -1.0681478e-03 -6.1037019e-05 ... -9.1555528e-05\n",
      " -1.2207404e-04 -1.5259255e-04]\n",
      "The main sound is: Speech\n",
      "[-1.8311106e-04 -9.1555528e-05 -2.4414808e-04 ...  6.1037019e-05\n",
      " -1.5259255e-04 -2.4414808e-04]\n",
      "The main sound is: Robot_moving\n",
      "[-1.5259255e-04 -3.0518509e-05  0.0000000e+00 ...  0.0000000e+00\n",
      " -2.1362957e-04 -1.5259255e-04]\n",
      "The main sound is: Beep\n",
      "[-3.0518509e-05 -6.1037019e-05 -3.0518509e-05 ...  8.8503677e-04\n",
      "  1.6785180e-03  1.0681478e-03]\n",
      "The main sound is: Speech\n",
      "[-0.00067141 -0.00030519  0.00076296 ...  0.00088504  0.00064089\n",
      "  0.00057985]\n",
      "The main sound is: Speech\n",
      "[ 6.408887e-04  6.408887e-04  5.798517e-04 ... -9.155553e-05  0.000000e+00\n",
      "  6.103702e-05]\n",
      "The main sound is: Robot_moving\n",
      "[ 3.0518509e-05 -1.2207404e-04 -1.2207404e-04 ... -1.5259255e-04\n",
      " -6.1037019e-05 -1.2207404e-04]\n",
      "The main sound is: Speech\n",
      "[-6.1037019e-05 -6.1037019e-05 -3.0518509e-05 ...  2.1362957e-04\n",
      "  2.7466659e-04  9.1555528e-05]\n",
      "The main sound is: Speech\n",
      "[-3.051851e-05  3.051851e-05  0.000000e+00 ...  6.103702e-05  0.000000e+00\n",
      " -6.103702e-05]\n",
      "The main sound is: Speech\n",
      "[-0.00030519 -0.00036622 -0.0003357  ...  0.00018311  0.00021363\n",
      "  0.00027467]\n",
      "The main sound is: Speech\n",
      "[ 2.4414808e-04  1.2207404e-04  9.1555528e-05 ... -9.1555528e-05\n",
      "  0.0000000e+00  3.0518509e-05]\n",
      "The main sound is: Speech\n",
      "[ 0.0000000e+00 -1.5259255e-04 -1.8311106e-04 ... -6.1037019e-05\n",
      " -1.5259255e-04 -1.5259255e-04]\n",
      "The main sound is: Speech\n",
      "[-2.1362957e-04 -1.5259255e-04 -3.0518509e-05 ...  0.0000000e+00\n",
      " -3.0518509e-05  6.1037019e-05]\n",
      "The main sound is: Speech\n",
      "[ 1.2207404e-04  3.0518509e-05  1.5259255e-04 ... -3.0518509e-05\n",
      "  0.0000000e+00  1.5259255e-04]\n",
      "The main sound is: Speech\n"
     ]
    }
   ],
   "source": [
    "# Audio stream parameters\n",
    "import collections\n",
    "my_classes = ['Speech', 'Silence', 'Music', 'Beep', 'Robot_moving']\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000  # YAMNet expects 16kHz audio\n",
    "CHUNK = 8000  # Number of audio samples per frame\n",
    "#model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
    "audio_buffer = collections.deque(maxlen=RATE)\n",
    "\n",
    "def process_audio(audio_data):\n",
    "    # Convert audio data to float32\n",
    "    audio_data = audio_data.astype(np.float32)\n",
    "\n",
    "    # audio_data /= np.max(np.abs(audio_data))  # Now audio_data is in the range [0, 1]\n",
    "\n",
    "    # # Scale and shift to [-0.6, 0.7]\n",
    "    # min_val = -0.6\n",
    "    # max_val = 0.7\n",
    "    # audio_data = audio_data * (max_val - min_val) + min_val\n",
    "\n",
    "    # Normalize the audio data to the range [-1, 1]\n",
    "    audio_data =audio_data/ 32767\n",
    "    # audio_data = audio_data * (max_val - min_val) + min_val\n",
    "    print(audio_data)\n",
    "\n",
    "    # You might also consider standardizing the data (optional):\n",
    "    # audio_data = (audio_data - np.mean(audio_data)) / np.std(audio_data)\n",
    "    # print(audio_data)\n",
    "    # Make predictions\n",
    "    result = reloaded_model(audio_data)\n",
    "    prediction=my_classes[tf.argmax(result['output_0'])]\n",
    "\n",
    "    # Post-process the scores\n",
    "    # predictions = np.mean(scores, axis=0)\n",
    "    # top_class = np.argmax(predictions)\n",
    "    # top_score = predictions[top_class]\n",
    "    \n",
    "    print(f'The main sound is: {prediction}')\n",
    "\n",
    "    #print(f\"Predicted class: {top_class}, Score: {top_score}\")\n",
    "\n",
    "def audio_callback(in_data, frame_count, time_info, status):\n",
    "    # Process the audio data here\n",
    "    audio_data = np.frombuffer(in_data, dtype=np.int16)\n",
    "    # You can pass this data to your model for prediction\n",
    "    process_audio(audio_data)\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK,\n",
    "                stream_callback=audio_callback)\n",
    "\n",
    "stream.start_stream()\n",
    "\n",
    "try:\n",
    "    while stream.is_active():\n",
    "        pass  # Keep the stream active\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "# Load the YAMNet model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average argmax: 57864.22727272727\n",
      "Average argmin: 60761.545454545456\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def process_wav_file(wav_file):\n",
    "    # Load the WAV file\n",
    "    audio = load_wav_16k_mono(wav_file)\n",
    "    #audio, _ = tf.audio.decode_wav(audio_binary)\n",
    "\n",
    "    # Flatten the audio tensor\n",
    "    # audio_flat = tf.reshape(audio, [-1])\n",
    "\n",
    "    # Calculate argmax and argmin\n",
    "    max_index = tf.argmax(audio)\n",
    "    min_index = tf.argmin(audio)\n",
    "\n",
    "    return max_index, min_index\n",
    "\n",
    "def compute_average_argmax_argmin(wav_files):\n",
    "    max_indices = []\n",
    "    min_indices = []\n",
    "\n",
    "    for wav_file in wav_files:\n",
    "        max_index, min_index = process_wav_file(wav_file)\n",
    "        max_indices.append(max_index.numpy())\n",
    "        min_indices.append(min_index.numpy())\n",
    "\n",
    "    # Compute average of max and min indices\n",
    "    avg_max_index = np.mean(max_indices)\n",
    "    avg_min_index = np.mean(min_indices)\n",
    "\n",
    "    return avg_max_index, avg_min_index\n",
    "\n",
    "# Replace this with the path to your folder containing WAV files\n",
    "wav_folder = '/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence'\n",
    "wav_files = glob.glob(os.path.join(wav_folder, '*.wav'))\n",
    "\n",
    "avg_max_index, avg_min_index = compute_average_argmax_argmin(wav_files)\n",
    "\n",
    "print(f\"Average argmax: {avg_max_index}\")\n",
    "print(f\"Average argmin: {avg_min_index}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### audio prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio_data(audio_data):\n",
    "    # Convert audio data to float32\n",
    "    audio_data = audio_data.astype(np.float32)\n",
    "    \n",
    "    # Normalize to the range [-1, 1]\n",
    "    audio_data /= np.max(np.abs(audio_data))\n",
    "    \n",
    "    return audio_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_route.c:877:(find_matching_chmap) Found no matching channel map\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling TFSMLayer.call().\n\n\u001b[1mGraph execution error:\n\nDetected at node yamnet_frames/tf_op_layer_Pad/Pad defined at (most recent call last):\n<stack traces unavailable>\nThe first dimension of paddings must be the rank of inputs[1,2] [1,1024]\n\t [[{{node yamnet_frames/tf_op_layer_Pad/Pad}}]] [Op:__inference_signature_wrapper___call___70676]\u001b[0m\n\nArguments received by TFSMLayer.call():\n   inputs=tf.Tensor(shape=(1, 1024), dtype=float32)\n   training=False\n   kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7864/144010677.py\u001b[0m in \u001b[0;36mcallback\u001b[0;34m(in_data, frame_count, time_info, status)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Process the audio data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7864/144010677.py\u001b[0m in \u001b[0;36mprocess_audio\u001b[0;34m(audio_data)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreloaded_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprediction_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling TFSMLayer.call().\n\n\u001b[1mGraph execution error:\n\nDetected at node yamnet_frames/tf_op_layer_Pad/Pad defined at (most recent call last):\n<stack traces unavailable>\nThe first dimension of paddings must be the rank of inputs[1,2] [1,1024]\n\t [[{{node yamnet_frames/tf_op_layer_Pad/Pad}}]] [Op:__inference_signature_wrapper___call___70676]\u001b[0m\n\nArguments received by TFSMLayer.call():\n   inputs=tf.Tensor(shape=(1, 1024), dtype=float32)\n   training=False\n   kwargs=<class 'inspect._empty'>"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "InvalidArgumentError.__init__() missing 3 required positional arguments: 'node_def', 'op', and 'message'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7864/144010677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Keep the stream open\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_active\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pyaudio/__init__.py\u001b[0m in \u001b[0;36mis_active\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \"\"\"\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stream_active\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mis_stopped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: InvalidArgumentError.__init__() missing 3 required positional arguments: 'node_def', 'op', and 'message'"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define constants\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 1024\n",
    "my_classes = ['Speech', 'Silence', 'Music', 'Beep', 'Robot_moving']\n",
    "\n",
    "# Load the trained model\n",
    "\n",
    "\n",
    "def process_audio(audio_data):\n",
    "    # Convert audio data to float32\n",
    "    audio_data = audio_data.astype(np.float32)\n",
    "    \n",
    "    # Normalize to the range [-1, 1]\n",
    "    audio_data /= np.max(np.abs(audio_data))\n",
    "    \n",
    "    # Ensure audio data is in the expected shape\n",
    "    audio_data = np.expand_dims(audio_data, axis=0)\n",
    "    \n",
    "    # Make predictions\n",
    "    result = reloaded_model(audio_data)\n",
    "    prediction_index = tf.argmax(result['output_0'], axis=-1).numpy()\n",
    "    prediction = my_classes[prediction_index[0]]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    # Convert in_data to numpy array\n",
    "    audio_data = np.frombuffer(in_data, dtype=np.int16)\n",
    "    \n",
    "    # Process the audio data\n",
    "    prediction = process_audio(audio_data)\n",
    "    print(\"Prediction:\", prediction)\n",
    "    \n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "try:\n",
    "    # Open the stream\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK,\n",
    "                    stream_callback=callback)\n",
    "    \n",
    "    # Start the stream\n",
    "    stream.start_stream()\n",
    "    \n",
    "    # Keep the stream open\n",
    "    while stream.is_active():\n",
    "        try:\n",
    "            pass\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "finally:\n",
    "    # Stop and close the stream\n",
    "    if stream.is_active():\n",
    "        stream.stop_stream()\n",
    "    stream.close()\n",
    "    \n",
    "    # Terminate PyAudio\n",
    "    p.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_directories(base_path, class_folders):\n",
    "    # List to hold information about each file\n",
    "    data = []\n",
    "    \n",
    "    # Loop through each class folder\n",
    "    for class_name in class_folders:\n",
    "        class_path = os.path.join(base_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            # List all .wav files in the class folder\n",
    "            for filename in os.listdir(class_path):\n",
    "                if filename.endswith('.wav'):\n",
    "                    file_path = os.path.join(class_path, filename)\n",
    "                    data.append({'filename': file_path, 'category': class_name})\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "base_data_path = '/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test'\n",
    "class_folders = ['Speech', 'Silence', 'Music', 'Beep', 'Robot_moving']\n",
    "t_df = create_dataframe_from_directories(base_data_path, class_folders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              filename      category  class_id\n",
      "0    /home/focus/Bureau/Audio_Node/src/resources/ra...        Speech         0\n",
      "1    /home/focus/Bureau/Audio_Node/src/resources/ra...        Speech         0\n",
      "2    /home/focus/Bureau/Audio_Node/src/resources/ra...        Speech         0\n",
      "3    /home/focus/Bureau/Audio_Node/src/resources/ra...        Speech         0\n",
      "4    /home/focus/Bureau/Audio_Node/src/resources/ra...        Speech         0\n",
      "..                                                 ...           ...       ...\n",
      "118  /home/focus/Bureau/Audio_Node/src/resources/ra...  Robot_moving         4\n",
      "119  /home/focus/Bureau/Audio_Node/src/resources/ra...  Robot_moving         4\n",
      "120  /home/focus/Bureau/Audio_Node/src/resources/ra...  Robot_moving         4\n",
      "121  /home/focus/Bureau/Audio_Node/src/resources/ra...  Robot_moving         4\n",
      "122  /home/focus/Bureau/Audio_Node/src/resources/ra...  Robot_moving         4\n",
      "\n",
      "[123 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define your classes and map them to IDs\n",
    "my_classes = ['Speech', 'Silence', 'Music', 'Beep', 'Robot_moving']\n",
    "map_class_to_id = {cls: idx for idx, cls in enumerate(my_classes)}\n",
    "\n",
    "# Filter DataFrame for specified classes (if needed)\n",
    "filtered_df = t_df[t_df['category'].isin(my_classes)]\n",
    "\n",
    "# Map class names to IDs\n",
    "filtered_df['class_id'] = filtered_df['category'].apply(lambda name: map_class_to_id[name])\n",
    "\n",
    "# Optionally, add a full path column if needed\n",
    "#filtered_df['full_path'] = filtered_df['filename'].apply(lambda row: os.path.abspath(row))\n",
    "\n",
    "# Display the DataFrame\n",
    "print(filtered_df.head(550))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/-pjK2u3Qtxc_230.0-240.0.wav', Class ID = 0\n",
      "Sample 2: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/-twSsq6Rj_I_140.0-150.0.wav', Class ID = 1\n",
      "Sample 3: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/0VRt6ENphpA_80.0-90.0.wav', Class ID = 1\n",
      "Sample 4: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/-iGr_xpHqCk_360.0-370.0.wav', Class ID = 1\n",
      "Sample 5: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/MOotHT2iJzI_30.0-40.0.wav', Class ID = 3\n",
      "Sample 6: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/EotkYg493i0_7.0-17.0.wav', Class ID = 3\n",
      "Sample 7: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/iD7p9-Ds3Dw_3.0-13.0.wav', Class ID = 3\n",
      "Sample 8: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/IG-46YG2wpk_30.0-40.0.wav', Class ID = 3\n",
      "Sample 9: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/2dsY_AHDFc8_0.0-6.0.wav', Class ID = 0\n",
      "Sample 10: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/0w1DJl3BCrY_470.0-480.0.wav', Class ID = 2\n",
      "Sample 11: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/0qQL0t97qf8_110.0-120.0.wav', Class ID = 0\n",
      "Sample 12: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/0PK5AwgT84o_0.0-10.0.wav', Class ID = 1\n",
      "Sample 13: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/-z7_vq6OYb0_30.0-40.0.wav', Class ID = 0\n",
      "Sample 14: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/HEaMIcsB5zA_27.0-37.0.wav', Class ID = 3\n",
      "Sample 15: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/0wiQzgy8F7U_30.0-40.0.wav', Class ID = 2\n",
      "Sample 16: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/-QNnqpm9q-g_240.0-250.0.wav', Class ID = 1\n",
      "Sample 17: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/ALVM3sOLNUk_70.0-80.0.wav', Class ID = 3\n",
      "Sample 18: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/-DvxsHG1tuo_410.0-420.0.wav', Class ID = 0\n",
      "Sample 19: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/-0EWw7ZGgZw_0.0-10.0.wav', Class ID = 0\n",
      "Sample 20: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/-DvxsHG1tuo_410.0-420.0.wav', Class ID = 2\n",
      "Sample 21: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/Uu2Fxy4hNj0_0.0-9.0.wav', Class ID = 3\n",
      "Sample 22: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/kH-9Djm4K9c_30.0-40.0.wav', Class ID = 3\n",
      "Sample 23: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/VPCMQqflHus_0.0-9.0.wav', Class ID = 3\n",
      "Sample 24: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/9V7cUY986Ec_0.0-10.0.wav', Class ID = 0\n",
      "Sample 25: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/0iNkEzDn2ys_580.0-590.0.wav', Class ID = 0\n",
      "Sample 26: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/0Q5mzNz2hiA_0.0-10.0.wav', Class ID = 2\n",
      "Sample 27: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/04NgAOAZXWc_30.0-40.0.wav', Class ID = 1\n",
      "Sample 28: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/2zySE2UJSJ4_0.0-10.0.wav', Class ID = 0\n",
      "Sample 29: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/1fP9nwukYk4_0.0-10.0.wav', Class ID = 0\n",
      "Sample 30: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/6iawZ-TzFoo_4.0-14.0.wav', Class ID = 0\n",
      "Sample 31: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/-_OzT7Xyvok_30.0-40.0.wav', Class ID = 2\n",
      "Sample 32: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/-oVpfUHN3Ok_520.0-530.0.wav', Class ID = 1\n",
      "Sample 33: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/30MeepvvjDs_400.0-410.0.wav', Class ID = 1\n",
      "Sample 34: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/2IRvx2GQ39M_0.0-7.0.wav', Class ID = 1\n",
      "Sample 35: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/1xhwyUVSRQk_170.0-180.0.wav', Class ID = 2\n",
      "Sample 36: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/-2nPzdDQdPI_30.0-40.0.wav', Class ID = 3\n",
      "Sample 37: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/RPvqI4KYiO4_0.0-10.0.wav', Class ID = 3\n",
      "Sample 38: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/0TiNPUS8pjM_0.0-7.0.wav', Class ID = 1\n",
      "Sample 39: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Robot_moving/8.wav', Class ID = 4\n",
      "Sample 40: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/1c5rSQsqmBE_0.0-10.0.wav', Class ID = 2\n",
      "Sample 41: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/AGfOAoOIUkU_310.0-320.0.wav', Class ID = 0\n",
      "Sample 42: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/-kFa0c0StCs_30.0-40.0.wav', Class ID = 3\n",
      "Sample 43: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/NEVn3hJ4ChE_0.0-10.0.wav', Class ID = 3\n",
      "Sample 44: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/-iuUYyMOrjU_30.0-40.0.wav', Class ID = 2\n",
      "Sample 45: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Robot_moving/20.wav', Class ID = 4\n",
      "Sample 46: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/1J-v2SVsSPQ_21.0-31.0.wav', Class ID = 2\n",
      "Sample 47: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/zX6BiYMikxs_0.0-10.0.wav', Class ID = 0\n",
      "Sample 48: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/-30H9V1IKps_6.0-16.0.wav', Class ID = 0\n",
      "Sample 49: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/2ModUhHZVCU_0.0-10.0.wav', Class ID = 2\n",
      "Sample 50: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/-Xp975jWot0_140.0-150.0.wav', Class ID = 1\n",
      "Sample 51: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/-pJyY_p9Paw_110.0-120.0.wav', Class ID = 0\n",
      "Sample 52: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/0NbRRq0L8o8_0.0-10.0.wav', Class ID = 2\n",
      "Sample 53: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/PTAMIckdmo8_0.0-10.0.wav', Class ID = 3\n",
      "Sample 54: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/0LxKP-OVHfM_0.0-10.0.wav', Class ID = 0\n",
      "Sample 55: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/TMtJ0BJUF9Y_27.0-37.0.wav', Class ID = 3\n",
      "Sample 56: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/9IFnYvr7xBM_0.0-10.0.wav', Class ID = 0\n",
      "Sample 57: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Robot_moving/24.wav', Class ID = 4\n",
      "Sample 58: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Robot_moving/25.wav', Class ID = 4\n",
      "Sample 59: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/-T-ZI1MZ44g_40.0-50.0.wav', Class ID = 2\n",
      "Sample 60: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/7i9sTFnZ0p0_30.0-40.0.wav', Class ID = 1\n",
      "Sample 61: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/7RJb2ZHh2JM_22.0-32.0.wav', Class ID = 0\n",
      "Sample 62: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/B1Hg2-Gx5UA_210.0-220.0.wav', Class ID = 3\n",
      "Sample 63: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/0VIITf_iLoE_0.0-6.0.wav', Class ID = 2\n",
      "Sample 64: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/0TPOLU68O9s_8.0-18.0.wav', Class ID = 2\n",
      "Sample 65: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/7ItYW-0XFo0_0.0-10.0.wav', Class ID = 0\n",
      "Sample 66: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/HE_qvh0u3xU_0.0-2.0.wav', Class ID = 3\n",
      "Sample 67: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/WdRqE06mjno_30.0-40.0.wav', Class ID = 3\n",
      "Sample 68: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Robot_moving/4.wav', Class ID = 4\n",
      "Sample 69: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/FvHIEK4f1Qc_30.0-40.0.wav', Class ID = 3\n",
      "Sample 70: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/DzXHgNFWuF0_10.0-20.0.wav', Class ID = 3\n",
      "Sample 71: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/FdrAOWDr5G0_30.0-40.0.wav', Class ID = 3\n",
      "Sample 72: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/UMfMC4FMZGc_0.0-10.0.wav', Class ID = 1\n",
      "Sample 73: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/-NC5li0b4eY_30.0-40.0.wav', Class ID = 2\n",
      "Sample 74: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/8NtI7EArM5E_30.0-40.0.wav', Class ID = 0\n",
      "Sample 75: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/HFtdHCTpFog_0.0-9.0.wav', Class ID = 3\n",
      "Sample 76: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/-oP-XX28B0s_30.0-40.0.wav', Class ID = 2\n",
      "Sample 77: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/AHb6Z-g4QQM_5.0-15.0.wav', Class ID = 0\n",
      "Sample 78: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/1CKGuGiDxYA_40.0-50.0.wav', Class ID = 1\n",
      "Sample 79: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/KWVX98cjG5Q_0.0-10.0.wav', Class ID = 3\n",
      "Sample 80: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/CCKkWxbTfY0_0.0-4.0.wav', Class ID = 3\n",
      "Sample 81: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/4LpOwY7J8gY_30.0-40.0.wav', Class ID = 1\n",
      "Sample 82: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/9Whj_3-js9U_10.0-20.0.wav', Class ID = 0\n",
      "Sample 83: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/0DP_gznjP98_3.0-13.0.wav', Class ID = 3\n",
      "Sample 84: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/1_YHHL_t2GI_150.0-160.0.wav', Class ID = 2\n",
      "Sample 85: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/-b4BxG3vBT8_0.0-10.0.wav', Class ID = 0\n",
      "Sample 86: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/D5fuP0zTb9U_8.0-18.0.wav', Class ID = 3\n",
      "Sample 87: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/7rk62G1WyG8_30.0-40.0.wav', Class ID = 1\n",
      "Sample 88: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Robot_moving/12.wav', Class ID = 4\n",
      "Sample 89: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/-NPqCu4DyAM_30.0-40.0.wav', Class ID = 2\n",
      "Sample 90: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/FkUb2lGgPhk_0.0-10.0.wav', Class ID = 3\n",
      "Sample 91: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/0VcSPe-xT5Y_0.0-4.0.wav', Class ID = 2\n",
      "Sample 92: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/-CV46fL81w0_0.0-10.0.wav', Class ID = 1\n",
      "Sample 93: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/A8ED8Iix7XQ_190.0-200.0.wav', Class ID = 0\n",
      "Sample 94: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/QiEHFpKSlzE_3.0-13.0.wav', Class ID = 3\n",
      "Sample 95: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/-jogNJd5azg_0.0-10.0.wav', Class ID = 1\n",
      "Sample 96: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/mjYpSGVocWM_0.0-10.0.wav', Class ID = 3\n",
      "Sample 97: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/rprGjeItQvI_0.0-10.0.wav', Class ID = 3\n",
      "Sample 98: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/jklPXWVY718_0.0-3.0.wav', Class ID = 3\n",
      "Sample 99: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/1LqxWWqSQe4_30.0-40.0.wav', Class ID = 0\n",
      "Sample 100: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/0l1Z-qU6dtI_30.0-40.0.wav', Class ID = 0\n",
      "Sample 101: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/CJrIcrHrfM4_0.0-10.0.wav', Class ID = 3\n",
      "Sample 102: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/386I9SMtAGc_0.0-10.0.wav', Class ID = 0\n",
      "Sample 103: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/2MWzuMAxMlE_0.0-10.0.wav', Class ID = 1\n",
      "Sample 104: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/X-w4Qvib6XU_0.0-10.0.wav', Class ID = 3\n",
      "Sample 105: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Robot_moving/28.wav', Class ID = 4\n",
      "Sample 106: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/-v5tNN6YADM_0.0-10.0.wav', Class ID = 1\n",
      "Sample 107: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/-ToQFT3M-Vg_200.0-210.0.wav', Class ID = 2\n",
      "Sample 108: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/-PrGDPzUrQU_0.0-10.0.wav', Class ID = 0\n",
      "Sample 109: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/02R_w3cr1i4_5.0-15.0.wav', Class ID = 0\n",
      "Sample 110: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/-HlS6jz-f0I_170.0-180.0.wav', Class ID = 2\n",
      "Sample 111: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/02ebhUYT7ng_0.0-10.0.wav', Class ID = 1\n",
      "Sample 112: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/31BoAMcVMro_0.0-10.0.wav', Class ID = 0\n",
      "Sample 113: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/H4ReFvkqwwY_10.0-20.0.wav', Class ID = 3\n",
      "Sample 114: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/3e314hm-YC8_430.0-440.0.wav', Class ID = 0\n",
      "Sample 115: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/GU3MG2Bhspo_30.0-40.0.wav', Class ID = 3\n",
      "Sample 116: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Music/1Xzqp1_g7s4_60.0-70.0.wav', Class ID = 2\n",
      "Sample 117: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/OvVWnTSAoNE_30.0-40.0.wav', Class ID = 0\n",
      "Sample 118: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/1lF4g89LKmc_0.0-10.0.wav', Class ID = 0\n",
      "Sample 119: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/bYIYo0PZeis_0.0-10.0.wav', Class ID = 3\n",
      "Sample 120: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/-kGU5xVPeiY_8.0-18.0.wav', Class ID = 3\n",
      "Sample 121: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Silence/-fepUUrCXQ8_30.0-40.0.wav', Class ID = 1\n",
      "Sample 122: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Speech/0150dZu3Na8_0.0-8.0.wav', Class ID = 0\n",
      "Sample 123: Filename = b'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/fdata/test/Beep/IfxaGlHvbDg_0.0-10.0.wav', Class ID = 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filenames = filtered_df['filename'].tolist()\n",
    "targets = filtered_df['class_id'].tolist()\n",
    "\n",
    "test_main_ds = tf.data.Dataset.from_tensor_slices((filenames, targets))\n",
    "test_main_ds=test_main_ds.shuffle(buffer_size=1000)\n",
    "\n",
    "# Function to print dataset labels\n",
    "def print_dataset_labels(dataset, num_samples=500):\n",
    "    for i, (filename, target) in enumerate(dataset.take(num_samples)):\n",
    "\n",
    "            print(f\"Sample {i+1}: Filename = {filename.numpy()}, Class ID = {target.numpy()}\")\n",
    "        \n",
    "print_dataset_labels(test_main_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_wav_for_map(filename, label):\n",
    "  return load_wav_16k_mono(filename), label\n",
    "\n",
    "test_main_ds = test_main_ds.map(load_wav_for_map)\n",
    "test_main_ds.element_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dss = main_ds.take(123)\n",
    "test_dss = test_dss.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n   inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n   training=False\n   mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17899/675658121.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n   inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n   training=False\n   mask=None"
     ]
    }
   ],
   "source": [
    "loss, accuracy = my_model.evaluate(test_dss)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.argmax(result['output_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 0. First element had shape [159619] and element 16 had shape [54465]. [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17899/1685587893.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Iterate through the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    777\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3086\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3087\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5982\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5983\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 0. First element had shape [159619] and element 16 had shape [54465]. [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy()  # Use SparseCategoricalAccuracy for integer labels\n",
    "loss_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "# Iterate through the test dataset\n",
    "for inputs, labels in test_ds:\n",
    "    # Make predictions\n",
    "    predictions = my_model(inputs)\n",
    "    \n",
    "    # If predictions are in a dictionary, extract the relevant tensor\n",
    "    if isinstance(predictions, dict):\n",
    "        predictions = predictions['output_0']  # Adjust key based on your model's output\n",
    "\n",
    "    # Ensure predictions have the correct shape\n",
    "    if len(predictions.shape) == 1:\n",
    "        predictions = tf.expand_dims(predictions, axis=-1)\n",
    "    \n",
    "    # Check predictions shape\n",
    "    print(\"Predictions shape:\", predictions.shape)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(labels, predictions, from_logits=True)\n",
    "    loss_metric.update_state(tf.reduce_mean(loss))\n",
    "    \n",
    "    # Update accuracy\n",
    "    accuracy_metric.update_state(labels, tf.argmax(predictions, axis=-1))\n",
    "\n",
    "# Print results\n",
    "print(\"Test Loss:\", loss_metric.result().numpy())\n",
    "print(\"Test Accuracy:\", accuracy_metric.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Signatures:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TFSMLayer' object has no attribute 'signatures'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17899/3431301391.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Inspect available signatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Available Signatures:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msignature_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignature_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TFSMLayer' object has no attribute 'signatures'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the model\n",
    "\n",
    "\n",
    "# Inspect available signatures\n",
    "print(\"Available Signatures:\")\n",
    "for signature_key in reloaded_model.signatures:\n",
    "    print(signature_key)\n",
    "    signature = reloaded_model.signatures[signature_key]\n",
    "    print(\"Input Signature:\", signature.inputs)\n",
    "    print(\"Output Signature:\", signature.outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: /home/focus/Bureau/Audio_Node/src/resources/ray_audio//{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17899/21791693.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/focus/Bureau/Audio_Node/src/resources/ray_audio/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0mexport_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   saved_model_proto, debug_info = (\n\u001b[0;32m-> 1016\u001b[0;31m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m   \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \"\"\"\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   debug_info_path = file_io.join(\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cannot parse file {path_to_pbtxt}: {str(e)}.\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     raise IOError(\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;34mf\"SavedModel file does not exist at: {export_dir}{os.path.sep}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;34mf\"{{{constants.SAVED_MODEL_FILENAME_PBTXT}|\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /home/focus/Bureau/Audio_Node/src/resources/ray_audio//{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "dog = tf.saved_model.load('/home/focus/Bureau/Audio_Node/src/resources/ray_audio/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
